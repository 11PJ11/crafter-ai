---
template_type: "layer-4-review-feedback"
methodology: "nWave Layer 4 Adversarial Verification"
purpose: "Structured peer review feedback format for reviewer agents"
version: "1.0.0"

# ==================================================================================
# LAYER 4 PEER REVIEW FEEDBACK TEMPLATE
# ==================================================================================
# This template structures feedback from Layer 4 reviewer agents conducting
# independent peer review to reduce confirmation bias and improve artifact quality

metadata:
  template_name: "Layer 4 Peer Review Feedback Template"
  use_cases: "Requirements, architecture, acceptance tests, code review"
  output_format: "YAML structured feedback"

# ==================================================================================
# REVIEW FEEDBACK STRUCTURE
# ==================================================================================

review_feedback:
  review_id: "rev_YYYYMMDD_HHMMSS_artifact-name"
  artifact_reviewed: "path/to/artifact.md"
  reviewer: "reviewer-agent-id"
  review_date: "YYYY-MM-DDTHH:MM:SSZ"
  iteration_number: 1

  strengths:
    - "Clear business context with quantitative goals"
    - "Well-structured user stories following persona-based format"
    - "Strong stakeholder engagement evident in requirements"
    - "Good traceability between business objectives and features"

  issues_identified:
    confirmation_bias:
      - issue: "Requirements assume cloud deployment without explicit stakeholder requirement"
        impact: "May exclude on-premise deployment option, limiting solution space"
        recommendation: "Re-elicit deployment constraints from Infrastructure Lead. Document rationale if cloud required"
        severity: "high"
        location: "Section 'Infrastructure Requirements', line 42"

    completeness_gaps:
      - issue: "Performance requirement 'System should be fast' is vague and unmeasurable"
        impact: "Cannot validate through testing. Ambiguous for implementation team"
        recommendation: "Quantify with stakeholder: 'API responds within 2 seconds (p95) under 1000 concurrent users'"
        severity: "critical"
        location: "Non-functional Requirements, line 67"

    clarity_issues:
      - issue: "Acceptance criterion 'User can complete checkout' lacks specificity"
        impact: "Multiple interpretations possible. Testing criteria unclear"
        recommendation: "Add measurable success criteria: 'User completes checkout in under 3 clicks with order confirmation email sent'"
        severity: "medium"
        location: "User Story US-3, AC-3.1"

    testability_concerns:
      - issue: "Acceptance criteria contains implementation details rather than business outcomes"
        impact: "Couples tests to implementation. Reduces refactoring ability"
        recommendation: "Rewrite in business terms: 'Customer receives order confirmation' not 'System sends email via SendGrid'"
        severity: "high"
        location: "User Story US-2, AC-2.3"

  recommendations:
    1: "CRITICAL: Quantify all performance requirements with measurable thresholds"
    2: "HIGH: Re-elicit deployment constraints to validate cloud assumption"
    3: "HIGH: Rewrite implementation-coupled acceptance criteria in business language"
    4: "MEDIUM: Add specific success criteria to all 'can do X' acceptance criteria"

  approval_status: "rejected_pending_revisions"
  critical_issues_count: 1
  high_issues_count: 3
  medium_issues_count: 2
  low_issues_count: 0

  next_steps: |
    Address critical and high severity issues before re-submission:
    1. Quantify performance requirements with stakeholder input
    2. Validate deployment assumptions with Infrastructure Lead
    3. Rewrite testability-coupled acceptance criteria

    Estimated revision time: 2-3 business days
    Recommend: Schedule focused workshop to accelerate clarifications

# ==================================================================================
# SEVERITY CLASSIFICATION GUIDELINES
# ==================================================================================

severity_guidelines:
  critical:
    definition: "Blocks handoff. Must be resolved before proceeding to next wave"
    examples:
      - "Unmeasurable performance requirements"
      - "Missing error handling scenarios"
      - "Stakeholder consensus absent on core features"
      - "Non-testable acceptance criteria"

  high:
    definition: "Significant quality or bias issues. Strong recommendation to resolve"
    examples:
      - "Technology bias without documented rationale"
      - "Completeness gaps (missing stakeholders, scenarios)"
      - "Ambiguous requirements with multiple interpretations"
      - "Architectural bias without alternatives evaluated"

  medium:
    definition: "Quality improvements recommended. Not blocking but reduces risk"
    examples:
      - "Clarity improvements for better stakeholder understanding"
      - "Additional edge cases for comprehensive coverage"
      - "Naming consistency across requirements"
      - "Traceability link improvements"

  low:
    definition: "Minor improvements. Nice-to-have but not essential"
    examples:
      - "Formatting inconsistencies"
      - "Documentation structure suggestions"
      - "Additional examples for clarity"
      - "Reference link additions"

# ==================================================================================
# APPROVAL STATUS DEFINITIONS
# ==================================================================================

approval_statuses:
  approved:
    condition: "No critical or high issues. Medium/low issues acceptable"
    action: "Artifact approved for handoff to next wave"
    handoff: "Proceed with handoff package preparation"

  conditionally_approved:
    condition: "High issues have explicit acceptance rationale. No critical issues"
    action: "Artifact approved with caveats documented"
    handoff: "Proceed but attach caveat documentation"

  rejected_pending_revisions:
    condition: "Critical or unresolved high issues present"
    action: "Primary agent must address issues and re-submit"
    handoff: "Blocked until issues resolved"

# ==================================================================================
# ISSUE CATEGORIZATION BY AGENT TYPE
# ==================================================================================

agent_specific_categories:
  business_analyst_reviewer:
    confirmation_bias: "Technology bias, happy path bias, availability bias"
    completeness_gaps: "Missing stakeholders, scenarios, requirements, constraints"
    clarity_issues: "Ambiguous requirements, vague criteria, unmeasurable outcomes"
    testability_concerns: "Non-testable acceptance criteria, missing validation approach"

  solution_architect_reviewer:
    architectural_bias: "Technology preference, familiarity bias, vendor bias"
    adr_quality: "Missing trade-offs, alternatives not evaluated, rationale unclear"
    feasibility_concerns: "Technical feasibility, team capability, resource constraints"
    boundary_clarity: "Component boundaries unclear, responsibilities overlapping"

  acceptance_designer_reviewer:
    happy_path_bias: "Error scenarios < 40%, insufficient edge cases"
    gwt_compliance: "Technical terms in scenarios, non-business language"
    coverage_completeness: "Missing user stories, incomplete scenario coverage"
    tdd_readiness: "Tests not executable, not initially failing, don't drive implementation"

  software_crafter_reviewer:
    implementation_bias: "Over-engineering, premature optimization, YAGNI violations"
    test_quality: "Test doubles for domain, shared mutable state, implementation coupling"
    code_readability: "How-comments, non-intention-revealing names, complex methods"
    acceptance_coverage: "Missing acceptance criteria tests, insufficient coverage"

# ==================================================================================
# USAGE EXAMPLES
# ==================================================================================

usage_example:
  scenario: "Business analyst reviewer critiques requirements document"

  input:
    artifact: "docs/requirements/requirements.md"
    reviewer: "business-analyst-reviewer"

  output:
    review_id: "rev_20251006_143022_requirements"
    artifact_reviewed: "docs/requirements/requirements.md"
    reviewer: "business-analyst-reviewer"
    review_date: "2025-10-06T14:30:22Z"
    iteration_number: 1

    strengths:
      - "Clear business objectives with measurable success criteria (45% â†’ 25% cart abandonment)"
      - "Strong stakeholder identification (Product Owner, UX Designer, Payment Lead)"

    issues_identified:
      confirmation_bias:
        - issue: "AWS deployment assumed without stakeholder validation"
          severity: "high"
          location: "Infrastructure section, line 58"

      completeness_gaps:
        - issue: "Performance requirements vague ('System should be fast')"
          severity: "critical"
          location: "Non-functional requirements, line 67"

    approval_status: "rejected_pending_revisions"
    critical_issues_count: 1
    high_issues_count: 1
