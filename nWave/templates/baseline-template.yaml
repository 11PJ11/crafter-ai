# =============================================================================
# BASELINE FILE TEMPLATE
# =============================================================================
# Purpose: Establish quantitative baseline BEFORE roadmap creation
# Usage: Copy this file to docs/feature/{project-id}/baseline.yaml
# Command: /nw:baseline "{goal-description}"
# =============================================================================
#
# This file is REQUIRED before running /nw:roadmap.
# It ensures measurement-first approach prevents wrong-problem prioritization.
#
# VALIDATION RULES:
# - All numeric fields MUST contain actual numbers, NOT placeholders
# - Type field determines which sections are required
# - Fields marked (REQUIRED) must be filled in
# - Fields marked (OPTIONAL) can be removed if not applicable
#
# =============================================================================

baseline:
  # ---------------------------------------------------------------------------
  # METADATA (REQUIRED for all types)
  # ---------------------------------------------------------------------------
  project_id: "your-project-id"  # (REQUIRED) kebab-case, matches feature folder
  created: "2025-01-01T00:00:00Z"  # (REQUIRED) ISO-8601 timestamp
  type: "performance_optimization"  # (REQUIRED) One of: performance_optimization | process_improvement | feature_development
  author: "researcher"  # (REQUIRED) human | researcher

  # ---------------------------------------------------------------------------
  # PROBLEM STATEMENT (REQUIRED for all types)
  # ---------------------------------------------------------------------------
  problem_statement:
    summary: "One sentence describing the problem"  # (REQUIRED)
    evidence: "How we know this is a problem (metrics, incidents, user feedback)"  # (REQUIRED)
    scope:  # (REQUIRED)
      in_scope:
        - "What IS included in this effort"
      out_of_scope:
        - "What is explicitly NOT included"

  # ===========================================================================
  # TYPE 1: PERFORMANCE OPTIMIZATION
  # ===========================================================================
  # Use when: Improving speed, reducing resource usage, optimizing throughput
  # REQUIRED sections: measurements, target, quick_wins
  # ---------------------------------------------------------------------------

  measurements:  # (REQUIRED for performance_optimization)
    baseline_metric:
      name: "total_execution_time"  # What are we measuring?
      value: 532  # (REQUIRED) MUST be a NUMBER - actual measured value
      unit: "seconds"  # Unit of measurement
      measured_at: "2025-01-01T10:00:00Z"  # When was this measured?
      measurement_method: "CI pipeline timer for full test suite"  # How was this measured?

    # Breakdown shows WHERE the time/resources are spent
    # REQUIRED: At least 2 categories to show distribution
    breakdown:
      - category: "tier2_integration_tests"
        value: 532  # (REQUIRED) MUST be a NUMBER
        unit: "seconds"
        percentage: 70  # (REQUIRED) Percentage of total
        notes: "8m 52s - largest contributor"
      - category: "tier3_e2e_tests"
        value: 228  # (REQUIRED) MUST be a NUMBER
        unit: "seconds"
        percentage: 30
        notes: "3m 48s - secondary contributor"

    # Bottleneck ranking identifies priorities by IMPACT
    # REQUIRED: Ranked list with #1 bottleneck clearly identified
    bottleneck_ranking:
      - rank: 1
        component: "tier2_integration_tests"
        impact: "70% of total execution time"
        quick_win_possible: true
        quick_win_description: "80% of these tests can parallelize with config change only"
        quick_win_effort: "LOW"  # LOW | MEDIUM | HIGH
      - rank: 2
        component: "tier3_e2e_tests"
        impact: "30% of total execution time"
        quick_win_possible: false
        quick_win_description: "Requires credential isolation infrastructure"
        quick_win_effort: "HIGH"

  # Target defines success criteria with evidence
  target:  # (REQUIRED for performance_optimization)
    metric: "total_execution_time"
    current: 532  # (REQUIRED) MUST match baseline_metric.value
    proposed: 180  # (REQUIRED) Target value - MUST be achievable
    unit: "seconds"
    improvement_factor: "3x"  # How much better?
    evidence_achievable: |
      Based on breakdown analysis:
      - Tier 2 parallelization (80% of 70%): ~5 minute savings
      - Estimated remaining: ~3 minutes
      - Target of 180s (3 min) is achievable with parallelization

  # Quick wins identify low-effort high-impact opportunities
  # REQUIRED: At least 1 quick win if largest bottleneck has one
  quick_wins:  # (REQUIRED for performance_optimization)
    - action: "Enable xUnit parallelization for non-SISTER tests"
      effort: "LOW"  # LOW | MEDIUM | HIGH
      expected_impact: "~5 minutes saved (80% of tier 2 tests)"
      impact_effort_ratio: "HIGH"  # HIGH | MEDIUM | LOW
      implementation_notes: "Configuration change only - no code required"
    - action: "Optimize test database initialization"
      effort: "MEDIUM"
      expected_impact: "~30 seconds saved"
      impact_effort_ratio: "MEDIUM"
      implementation_notes: "Requires shared test fixture setup"

  # ===========================================================================
  # TYPE 2: PROCESS IMPROVEMENT
  # ===========================================================================
  # Use when: Fixing workflow issues, preventing incidents, improving reliability
  # REQUIRED sections: qualitative_evidence, simplest_alternatives_considered
  # ---------------------------------------------------------------------------

  qualitative_evidence:  # (REQUIRED for process_improvement)
    # Incident references provide concrete evidence
    # REQUIRED: At least one of incident_references OR failure_modes
    incident_references:
      - id: "ROADMAP-2025-12-03-001"
        date: "2025-12-03"
        summary: "Roadmap optimized wrong bottleneck"
        root_cause: "No measurement data before roadmap creation"
        link: "docs/agent-improvements/2025-12-03_roadmap-prioritization-lessons.md"
      - id: "INCIDENT-EXAMPLE-002"
        date: "2025-01-15"
        summary: "Second example incident"
        root_cause: "Root cause description"
        link: "path/to/incident/doc.md"

    # Failure modes describe patterns of problems
    failure_modes:
      - name: "Architecture Before Measurement"
        frequency: "Common - observed in 3 of 5 recent roadmaps"
        impact: "Wasted effort on wrong solutions"
        evidence: "Incident ROADMAP-2025-12-03-001 is primary example"
      - name: "Constraint-Anchored Architecture"
        frequency: "Occasional"
        impact: "Over-engineering for minority constraints"
        evidence: "SISTER constraint dominated 20% problem"

    # Stakeholder input captures concerns from team
    stakeholder_input:  # (OPTIONAL)
      - source: "Tech Lead"
        concern: "Agents skip measurement when under time pressure"
        proposed_solution: "Make measurement a blocking prerequisite"
      - source: "Product Owner"
        concern: "Roadmaps often miss quick wins"
        proposed_solution: "Require quick-win analysis before architecture"

  # ===========================================================================
  # TYPE 3: FEATURE DEVELOPMENT
  # ===========================================================================
  # Use when: Building new capabilities, adding features, greenfield development
  # REQUIRED sections: current_state, requirements_source
  # ---------------------------------------------------------------------------

  current_state:  # (REQUIRED for feature_development)
    description: "No baseline command exists - greenfield development"
    # For brownfield (existing code):
    # description: "Current implementation uses manual approach"
    capabilities:  # What exists today?
      - "/nw:roadmap command exists"
      - "Manual measurement possible via CI/profiling"
    limitations:  # What's missing?
      - "No enforcement of measurement-first approach"
      - "No standardized baseline file format"
      - "No command to guide baseline creation"

  requirements_source:  # (REQUIRED for feature_development)
    origin: "Incident analysis ROADMAP-2025-12-03-001"
    validation: "Reviewed with team, confirmed as priority"
    requirements:  # (OPTIONAL) List specific requirements
      - "Must block /nw:roadmap without baseline file"
      - "Must support three baseline types"
      - "Must integrate with researcher agent for data gathering"

  # ===========================================================================
  # COMMON: SIMPLEST ALTERNATIVES CONSIDERED
  # ===========================================================================
  # REQUIRED for: process_improvement
  # RECOMMENDED for: feature_development, performance_optimization
  # ---------------------------------------------------------------------------

  simplest_alternatives_considered:
    - alternative: "Add checklist item to /nw:roadmap command"
      description: "Single line reminder to measure first"
      why_insufficient: |
        Checklists are advisory, not blocking. The incident showed agents
        already had similar guidance but placed measurement AFTER solution design.
        A checklist would be ignored the same way.
      verdict: "INSUFFICIENT"  # INSUFFICIENT | PARTIAL | ADEQUATE
    - alternative: "Add reminder note to solution-architect principles"
      description: "Core principle saying 'remember to measure'"
      why_insufficient: |
        Core principles are guidance, not enforcement. The incident showed
        agents followed other principles but not measurement-first.
        Non-blocking guidance was insufficient.
      verdict: "INSUFFICIENT"
    - alternative: "Add Priority Validation to review only"
      description: "Reviewer checks if measurement data exists"
      why_insufficient: |
        Reviews happen AFTER roadmap creation. The entire 34-step roadmap
        was created before review. Prevention is cheaper than detection.
        Good secondary layer but needs earlier gate.
      verdict: "PARTIAL"

  # ===========================================================================
  # VALIDATION STATUS
  # ===========================================================================
  # Track review and approval of this baseline
  # ---------------------------------------------------------------------------

  validation:
    status: "complete"  # complete | draft | needs_review
    validated_by: "researcher"  # human | agent | reviewer
    validation_date: "2025-01-01"
    notes: "Baseline established from CI metrics and incident analysis"  # (OPTIONAL)

# =============================================================================
# EXAMPLE: MINIMAL PERFORMANCE OPTIMIZATION BASELINE
# =============================================================================
# This shows the minimum required fields for a performance optimization:
#
# baseline:
#   project_id: "test-optimization"
#   created: "2025-01-01T00:00:00Z"
#   type: "performance_optimization"
#   author: "researcher"
#
#   problem_statement:
#     summary: "Tests take too long in CI"
#     evidence: "CI pipeline averages 12 minutes, blocking PRs"
#     scope:
#       in_scope: ["Unit tests", "Integration tests"]
#       out_of_scope: ["E2E tests"]
#
#   measurements:
#     baseline_metric:
#       name: "total_test_time"
#       value: 720
#       unit: "seconds"
#       measured_at: "2025-01-01T10:00:00Z"
#       measurement_method: "CI timer"
#     breakdown:
#       - category: "unit_tests"
#         value: 120
#         unit: "seconds"
#         percentage: 17
#       - category: "integration_tests"
#         value: 600
#         unit: "seconds"
#         percentage: 83
#     bottleneck_ranking:
#       - rank: 1
#         component: "integration_tests"
#         impact: "83% of total"
#         quick_win_possible: true
#         quick_win_description: "Parallelization"
#         quick_win_effort: "LOW"
#
#   target:
#     metric: "total_test_time"
#     current: 720
#     proposed: 240
#     unit: "seconds"
#     improvement_factor: "3x"
#     evidence_achievable: "Parallelization can reduce integration by 75%"
#
#   quick_wins:
#     - action: "Enable parallel test execution"
#       effort: "LOW"
#       expected_impact: "~6 minute savings"
#       impact_effort_ratio: "HIGH"
#
#   validation:
#     status: "complete"
#     validated_by: "researcher"
#     validation_date: "2025-01-01"
#
# =============================================================================
# EXAMPLE: MINIMAL PROCESS IMPROVEMENT BASELINE
# =============================================================================
#
# baseline:
#   project_id: "roadmap-prioritization-fix"
#   created: "2025-12-03T00:00:00Z"
#   type: "process_improvement"
#   author: "human"
#
#   problem_statement:
#     summary: "Roadmaps address wrong problems"
#     evidence: "Incident ROADMAP-2025-12-03-001"
#     scope:
#       in_scope: ["Roadmap creation process"]
#       out_of_scope: ["Implementation process"]
#
#   qualitative_evidence:
#     incident_references:
#       - id: "ROADMAP-2025-12-03-001"
#         date: "2025-12-03"
#         summary: "Optimized wrong bottleneck"
#         root_cause: "No measurement before planning"
#         link: "docs/agent-improvements/..."
#     failure_modes:
#       - name: "Architecture Before Measurement"
#         frequency: "Common"
#         impact: "Wasted effort"
#         evidence: "Incident analysis"
#
#   simplest_alternatives_considered:
#     - alternative: "Add checklist"
#       description: "Reminder to measure"
#       why_insufficient: "Checklists can be ignored"
#       verdict: "INSUFFICIENT"
#     - alternative: "Add to principles"
#       description: "Core principle update"
#       why_insufficient: "Principles are guidance, not blocking"
#       verdict: "INSUFFICIENT"
#
#   validation:
#     status: "complete"
#     validated_by: "human"
#     validation_date: "2025-12-03"
#
# =============================================================================
