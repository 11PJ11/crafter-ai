{
  "project_id": "plugin-marketplace-migration",
  "step_id": "02-04",
  "phase": 2,
  "step": "2.4",
  "name": "Capture Token Baseline Measurements",
  "description": "Measure and archive current MD file token counts to establish baseline for SC7 validation (target: ~60% token savings)",
  "estimated_hours": "1-2",
  "agent": "@software-crafter",
  "priority": "HIGH",
  "context": {
    "motivation": "SC7 in Phase 8 requires baseline measurements to validate token savings. Without this baseline, SC7 is unvalidatable.",
    "dependencies": [
      "2.3"
    ],
    "blocking_conditions": [
      "All agent .md files must exist in nWave/agents/",
      "All command .md files must exist in nWave/commands/",
      "Token counting methodology must be defined"
    ],
    "success_criteria_mapping": {
      "SC7": "Token count improvements measured and documented"
    }
  },
  "deliverables": [
    {
      "path": "baseline/token-measurements/phase-2-baseline.json",
      "description": "JSON file containing token measurements for all agents and commands"
    },
    {
      "path": "tools/measure-tokens.py",
      "description": "Python script for measuring token counts using tiktoken"
    },
    {
      "path": "baseline/token-measurements/README.md",
      "description": "Documentation of measurement methodology"
    }
  ],
  "acceptance_criteria": [
    {
      "id": "AC1",
      "description": "Baseline captures ALL 26 agents + 20 commands MD file sizes",
      "validation": "Verify 46 files measured in baseline JSON"
    },
    {
      "id": "AC2",
      "description": "Measurements include: file_path, byte_count, line_count, token_count (using tiktoken)",
      "validation": "Each file entry contains all four measurements"
    },
    {
      "id": "AC3",
      "description": "Baseline stored in JSON format with timestamp",
      "validation": "JSON includes ISO 8601 timestamp and valid structure"
    },
    {
      "id": "AC4",
      "description": "Measurement methodology documented",
      "validation": "README.md explains tiktoken cl100k_base encoding usage"
    },
    {
      "id": "AC5",
      "description": "Script is reusable for Phase 8 comparison",
      "validation": "Script accepts command-line arguments and produces consistent output"
    },
    {
      "id": "AC6",
      "description": "All files validated (exist and readable)",
      "validation": "Script exits with error code if any file missing or unreadable"
    }
  ],
  "execution_guidance": {
    "approach": "Outside-In TDD",
    "steps": [
      {
        "order": 1,
        "description": "Create measure-tokens.py script with CLI interface",
        "notes": "Use argparse for --input-dir and --output-file arguments"
      },
      {
        "order": 2,
        "description": "Implement file discovery and validation",
        "notes": "Use pathlib to find all .md files recursively"
      },
      {
        "order": 3,
        "description": "Implement token counting using tiktoken cl100k_base",
        "notes": "Import tiktoken, use encoding.encode() to count tokens"
      },
      {
        "order": 4,
        "description": "Generate JSON output with required structure",
        "notes": "Include timestamp, methodology, files array, summary"
      },
      {
        "order": 5,
        "description": "Run script against nWave/agents/ and nWave/commands/",
        "notes": "Execute manually to create baseline/token-measurements/phase-2-baseline.json"
      },
      {
        "order": 6,
        "description": "Document methodology in README.md",
        "notes": "Explain tiktoken usage, encoding choice, reproduction steps"
      }
    ]
  },
  "quality_gates": [
    {
      "gate": "All 46 files measured",
      "validation": "Count entries in baseline JSON files array"
    },
    {
      "gate": "Token counts are consistent",
      "validation": "Running script twice produces identical token counts"
    },
    {
      "gate": "JSON is valid and parseable",
      "validation": "json.loads() succeeds without errors"
    },
    {
      "gate": "Script handles errors gracefully",
      "validation": "Missing files produce clear error messages"
    }
  ],
  "error_handling": {
    "missing_files": "Script exits with code 1 and lists missing files",
    "unreadable_files": "Script exits with code 1 and reports permission errors",
    "tiktoken_import_error": "Script exits with code 1 and suggests: pip install tiktoken",
    "invalid_output_path": "Script exits with code 1 if output directory doesn't exist"
  },
  "test_specifications": {
    "outer_loop": {
      "test": "E2E: Baseline file created with correct structure",
      "validation": "Load JSON, verify timestamp, methodology, files, summary keys exist"
    },
    "inner_loop": [
      {
        "test": "test_all_agents_measured",
        "description": "Verify 26 agent files in baseline",
        "assertion": "Count files with path matching nWave/agents/*.md == 26"
      },
      {
        "test": "test_all_commands_measured",
        "description": "Verify 20 command files in baseline",
        "assertion": "Count files with path matching nWave/commands/*.md == 20"
      },
      {
        "test": "test_baseline_includes_metadata",
        "description": "Verify timestamp and methodology present",
        "assertion": "JSON contains 'timestamp' (ISO 8601) and 'methodology' keys"
      },
      {
        "test": "test_token_counting_consistent",
        "description": "Same file produces same token count",
        "assertion": "Run twice, compare token_count for each file - must match"
      },
      {
        "test": "test_baseline_json_valid",
        "description": "JSON is well-formed and parseable",
        "assertion": "json.loads() succeeds, schema validation passes"
      }
    ]
  },
  "notes": [
    "This step establishes the baseline BEFORE Phase 3-7 refactoring",
    "Phase 8 will re-run this script and compare to validate SC7 (~60% token savings)",
    "Token counting uses tiktoken cl100k_base (GPT-4 encoding) for accuracy",
    "Baseline captures pre-YAML-migration state for comparison"
  ],
  "validation": {
    "status": "pending",
    "notes": "Step validation",
    "migrated_at": "2026-01-13T22:11:27.133289"
  }
}