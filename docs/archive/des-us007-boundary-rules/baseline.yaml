# Baseline Measurement for US-007: Boundary Rules for Scope Enforcement
# Feature Development - Prevent agent scope creep with explicit allowed/forbidden action definitions

metadata:
  project_id: des-us007-boundary-rules
  baseline_type: feature_development
  created_at: '2026-01-29'
  created_by: researcher (Nova)
  goal: >
    Implement BOUNDARY_RULES section in DES prompts to prevent agent scope creep
    with explicit allowed/forbidden action definitions and post-execution git diff
    validation

# ============================================================================
# CURRENT STATE ANALYSIS
# ============================================================================

current_state:
  environment: brownfield

  description: >
    The DES validation infrastructure already includes BOUNDARY_RULES as a mandatory
    section in prompts (line 66 of src/des/application/validator.py), BUT the section
    is not actually generated or enforced. The validator checks for the presence of
    "# BOUNDARY_RULES" in prompts, but the orchestrator only returns placeholder
    comments indicating this section should exist (line 374 of orchestrator.py).

    There is NO implementation of:
    1. BOUNDARY_RULES section generation with ALLOWED/FORBIDDEN file patterns
    2. Derivation of allowed patterns from step file scope
    3. Post-execution scope validation comparing git diff to allowed patterns
    4. Audit logging of scope violations

    The step file schema already includes a "scope" field with "target_files",
    "test_files", and "allowed_patterns" arrays (seen in test fixtures), providing
    the data source for boundary rules generation.

  existing_capabilities:
    validation_infrastructure:
      - "MandatorySectionChecker validates BOUNDARY_RULES section presence (validator.py:66)"
      - "PromptValidator facade exposes BOUNDARY_RULES in MANDATORY_SECTIONS list"
      - "Pre-invocation validation blocks Task invocation if BOUNDARY_RULES missing"
      - "SubagentStopHook exists for post-execution validation (orchestrator.py:394)"

    step_file_schema:
      - "Step files contain scope.target_files array"
      - "Step files contain scope.test_files array"
      - "Step files contain scope.allowed_patterns array"
      - "Schema v2.0 with 8-phase TDD cycle (phase_execution_log tracks changes)"

    audit_infrastructure:
      - "AuditLogger exists with structured event logging (adapters/driven/logging/audit_logger.py)"
      - "Event types include TASK_INVOCATION_STARTED, TASK_INVOCATION_VALIDATED"
      - "Audit log supports WARNING severity level for scope violations"

    git_integration:
      - "Step execution assumes git repository context"
      - "COMMIT phase in TDD cycle creates git commits"

  limitations:
    missing_components:
      - "No BOUNDARY_RULES template or renderer"
      - "No BoundaryRulesGenerator to create ALLOWED/FORBIDDEN lists"
      - "No ScopeValidator to compare git diff against allowed patterns"
      - "No scope violation detection in SubagentStopHook"
      - "No audit event type for SCOPE_VIOLATION"

    orchestrator_gaps:
      - "render_full_prompt() returns placeholder comment instead of actual BOUNDARY_RULES (line 374)"
      - "No integration point to generate boundary rules from step file scope"
      - "No post-execution git diff analysis"

    validation_gaps:
      - "Pre-invocation checks for section presence but cannot verify content quality"
      - "No validation that ALLOWED patterns match step scope"
      - "No validation that step file is implicitly allowed"

  why_insufficient: >
    The current placeholder approach allows agents to receive prompts that technically
    pass validation but provide zero scope enforcement. Agents have no explicit
    guidance on which files they can modify, leading to scope creep where agents
    "helpfully" improve unrelated files while working on a narrow task. This causes
    merge conflicts, delays releases, and makes PRs unpredictable (Priya's pain point
    from user story). The infrastructure exists but lacks the critical middle layer
    that generates, enforces, and audits boundary rules.

# ============================================================================
# REQUIREMENTS SOURCE
# ============================================================================

requirements_source:
  origin: user_story_validated

  user_story:
    id: US-007
    persona: Priya (Tech Lead)
    problem: >
      Priya reviewed a PR where the agent was supposed to implement one small feature
      but ended up refactoring three other files "while it was there." This scope creep
      caused merge conflicts and delayed the release.

    solution: >
      BOUNDARY_RULES section in prompts that explicitly defines ALLOWED and FORBIDDEN
      actions. Clear scope limitation to the assigned step only. Post-execution scope
      validation comparing git diff to allowed patterns.

    business_value:
      - "Prevents scope creep that causes merge conflicts and release delays"
      - "Ensures predictable, controlled modifications"
      - "Provides audit trail of scope violations for PR review"
      - "Allows Priya to catch unauthorized file changes before they cause problems"

  acceptance_criteria:
    - id: AC-007.1
      description: "BOUNDARY_RULES section included in all step execution prompts"
      test_scenarios: 2

    - id: AC-007.2
      description: "ALLOWED actions explicitly enumerated (step file, task files, tests)"
      test_scenarios: 2

    - id: AC-007.3
      description: "FORBIDDEN actions explicitly enumerated (other steps, other files)"
      test_scenarios: 2

    - id: AC-007.4
      description: "Scope validation runs post-execution (compare git diff to allowed patterns)"
      test_scenarios: 3

    - id: AC-007.5
      description: "Scope violations logged as warnings in audit trail"
      test_scenarios: 3

  validation_evidence:
    test_file: tests/des/acceptance/test_us007_boundary_rules.py
    total_scenarios: 14
    status: RED (Outside-In TDD - awaiting DEVELOP wave implementation)

    test_coverage:
      boundary_rules_inclusion:
        - "test_scenario_001_step_execution_prompt_includes_boundary_rules_section"

      allowed_actions:
        - "test_scenario_002_boundary_rules_enumerate_allowed_actions"
        - "test_scenario_003_allowed_patterns_match_step_target_files"

      forbidden_actions:
        - "test_scenario_004_boundary_rules_enumerate_forbidden_actions"
        - "test_scenario_005_forbidden_includes_continuation_to_next_step"

      scope_validation:
        - "test_scenario_006_scope_validation_detects_out_of_scope_modification"
        - "test_scenario_007_in_scope_modifications_pass_validation"
        - "test_scenario_008_step_file_modification_always_allowed"

      audit_logging:
        - "test_scenario_009_scope_violation_logged_to_audit_trail"
        - "test_scenario_010_multiple_scope_violations_all_logged"
        - "test_scenario_011_no_violations_no_warning_logs"

      completeness:
        - "test_scenario_012_boundary_rules_has_complete_structure"
        - "test_scenario_013_develop_command_also_includes_boundary_rules"
        - "test_scenario_014_missing_boundary_rules_blocks_invocation"

# ============================================================================
# BASELINE METRICS
# ============================================================================

baseline_metric:
  metric_name: scope_violations_prevented_per_execution
  description: >
    Number of scope violations detected and prevented per step execution.
    Currently 0 because no validation exists.
  value: 0
  unit: violations_prevented
  measurement_method: >
    Count of scope violations detected in audit log (event_type: SCOPE_VIOLATION).
    Currently measured by absence of ScopeValidator and audit events.
  measurement_date: '2026-01-29'
  measurement_notes: >
    No scope validation exists, so agents can modify any files without detection.
    This baseline represents the "unprotected" state before boundary rules enforcement.

secondary_metrics:
  - metric_name: prompts_with_boundary_rules
    current: 0
    target: 100
    unit: percentage
    notes: "Orchestrator generates placeholder comment, not actual BOUNDARY_RULES section"

  - metric_name: scope_violations_logged
    current: 0
    target: "all violations"
    unit: count
    notes: "No SCOPE_VIOLATION audit events exist in current implementation"

  - metric_name: git_diff_checks_per_execution
    current: 0
    target: 1
    unit: checks_per_execution
    notes: "SubagentStopHook does not perform git diff analysis"

# ============================================================================
# QUICK WIN ANALYSIS
# ============================================================================

quick_wins:
  analysis: >
    Given the existing infrastructure (validation, audit logging, step file schema),
    there are NO quick wins that deliver the core value. The feature requires:

    1. Template/renderer for BOUNDARY_RULES section (complex formatting)
    2. Logic to derive allowed patterns from step file scope (business rules)
    3. Git diff integration and pattern matching (external command execution)
    4. Scope validation integration into SubagentStopHook (validation logic)

    Each component is non-trivial and interdependent. Partial implementation would
    not provide Priya's desired outcome of preventing scope creep. The minimum viable
    feature requires all 4 components working together.

  identified_alternatives: none_viable

  alternatives_considered:
    - approach: "Generate static BOUNDARY_RULES section without scope derivation"
      rejected_reason: >
        Would pass validation but provide no actual scope enforcement. Generic
        "stay in scope" message doesn't prevent agents from modifying wrong files.

    - approach: "Add scope field to prompts without validation"
      rejected_reason: >
        Agents might ignore scope guidance without enforcement. Post-execution
        validation is critical for audit trail and catching violations.

    - approach: "Use existing tools (file watchers, linters) for scope checking"
      rejected_reason: >
        External tools don't integrate with DES audit trail, can't access step file
        scope definition, and don't provide agent-specific boundary guidance in prompts.

  recommendation: >
    Proceed with full feature implementation. The infrastructure is well-positioned
    for this addition, and the acceptance tests provide comprehensive coverage.
    No viable shortcuts exist that would deliver meaningful value.

# ============================================================================
# TARGET STATE
# ============================================================================

target:
  current: 0
  target: 100
  unit: percentage
  description: >
    Percentage of step executions that include BOUNDARY_RULES section with:
    - ALLOWED file patterns derived from step scope
    - FORBIDDEN actions (other steps, unrelated files, continuation)
    - Post-execution scope validation via git diff
    - Audit logging of any scope violations

  success_criteria:
    - "All 14 acceptance test scenarios pass (currently 0/14)"
    - "Orchestrator generates complete BOUNDARY_RULES section for execute/develop commands"
    - "ScopeValidator successfully detects out-of-scope modifications via git diff"
    - "SCOPE_VIOLATION events appear in audit log when violations occur"
    - "Agents receive explicit file pattern allowlist in every step execution prompt"

# ============================================================================
# IMPLEMENTATION CONSTRAINTS
# ============================================================================

constraints:
  technical:
    - "Must integrate with existing orchestrator.render_full_prompt() method"
    - "Must use existing step file scope schema (target_files, test_files, allowed_patterns)"
    - "Must work with both schema v1.0 (14 phases) and v2.0 (8 phases)"
    - "Git diff analysis must handle uncommitted changes and untracked files"
    - "Pattern matching must support glob patterns (**, *, exact paths)"

  compatibility:
    - "Cannot break existing validation for other mandatory sections"
    - "Must maintain backward compatibility with step files lacking scope field"
    - "Scope violations logged as WARNING (not ERROR) to allow Priya's discretion"

  operational:
    - "SubagentStopHook must complete scope validation without requiring user input"
    - "Scope validation failure should not block step completion (warnings only)"
    - "Audit log entries must include enough context for PR review"

# ============================================================================
# DEPENDENCIES AND RISKS
# ============================================================================

dependencies:
  internal:
    - component: "src/des/application/orchestrator.py"
      usage: "Must extend render_full_prompt() to generate BOUNDARY_RULES section"

    - component: "src/des/application/validator.py"
      usage: "Already validates BOUNDARY_RULES presence; may need content validation"

    - component: "src/des/adapters/driven/logging/audit_logger.py"
      usage: "Must add SCOPE_VIOLATION event type"

  external:
    - tool: git
      usage: "Git diff analysis for post-execution scope validation"
      availability: "Assumed present (DES operates in git repositories)"

  step_file_schema:
    - field: scope.target_files
      status: "Exists in test fixtures; may need to verify production usage"

    - field: scope.allowed_patterns
      status: "Exists in test fixtures; derivation logic needed if not populated"

risks:
  - risk: "Step files in production may not have scope field populated"
    mitigation: "Graceful degradation - generate generic BOUNDARY_RULES if scope missing"

  - risk: "Git diff may be unavailable or fail in non-git environments"
    mitigation: "Catch git command errors, log warning, skip scope validation"

  - risk: "Pattern matching complexity for glob patterns"
    mitigation: "Use fnmatch or pathlib for reliable glob pattern matching"

# ============================================================================
# SIMPLEST ALTERNATIVE ANALYSIS
# ============================================================================

simplest_alternative:
  analysis_required: true

  evaluation: >
    Feature complexity justified by business need. Priya experienced real production
    delays from scope creep. The 14 acceptance test scenarios reflect the comprehensive
    nature of the problem (prompt generation, validation, audit logging).

    The infrastructure (validation, audit, step schema) was designed to support this
    feature, suggesting it was anticipated as a necessary capability. No simpler
    external tool provides:
    1. Integration with DES prompts and step files
    2. Agent-specific scope guidance in Task prompts
    3. Audit trail integration for PR review

    Verdict: Full implementation justified. No viable simpler alternative exists.

  alternatives_evaluated:
    - option: "Manual PR review for scope violations"
      insufficient_because: "Reactive, time-consuming, doesn't prevent the problem"

    - option: "Git hooks to block out-of-scope commits"
      insufficient_because: "Prevents commits but doesn't guide agents during execution"

    - option: "Agent training to follow scope"
      insufficient_because: "Unreliable without explicit enforcement and validation"

# ============================================================================
# MEASUREMENT PLAN
# ============================================================================

measurement_plan:
  phase_1_post_implementation:
    - metric: prompts_with_boundary_rules
      method: "Count prompts containing '# BOUNDARY_RULES' + '# ALLOWED' + '# FORBIDDEN'"
      target: "100% of execute/develop command prompts"

    - metric: scope_violations_detected
      method: "Count SCOPE_VIOLATION audit events after running acceptance tests"
      target: ">0 (proves detection works)"

    - metric: test_pass_rate
      method: "pytest tests/des/acceptance/test_us007_boundary_rules.py"
      target: "14/14 scenarios pass"

  phase_2_production_validation:
    - metric: scope_violation_rate
      method: "SCOPE_VIOLATION events / total step executions"
      target: "<5% (proves agents mostly stay in scope)"

    - metric: false_positive_rate
      method: "User-reported cases of valid changes flagged as violations"
      target: "<1% (proves pattern matching accuracy)"

# ============================================================================
# RECOMMENDATIONS
# ============================================================================

recommendations:
  - priority: high
    recommendation: >
      Proceed with roadmap creation for full implementation. All 4 components
      (template generation, scope derivation, git diff validation, audit logging)
      are necessary and justified by business value.

  - priority: medium
    recommendation: >
      Verify step file scope field population in existing step files. If not widely
      used, may need migration or auto-derivation logic.

  - priority: low
    recommendation: >
      Consider adding scope validation to pre-invocation checks (validate allowed_patterns
      are non-empty) to catch configuration issues early.

# ============================================================================
# REVIEW METADATA
# ============================================================================

reviews:
  - reviewer: software-crafter-reviewer
    date: '2026-01-29T00:00:00Z'
    review_type: baseline
    overall_assessment: APPROVED
    ready_for_roadmap: true

    summary: >
      Exemplary baseline artifact with comprehensive analysis, accurate measurements,
      and thorough justification. The baseline correctly captures the "unprotected"
      state (zero scope enforcement), provides detailed evidence from code inspection,
      and establishes clear success criteria. All critical elements present with
      exceptional quality.

    strengths:
      - strength: "Comprehensive current state analysis with precise code references"
        evidence: "Lines 40-55 identify exact components (validator.py:66, orchestrator.py:374) with clear capability assessment"

      - strength: "Accurate baseline measurement methodology"
        evidence: "Baseline value of 0 correctly measured via absence of ScopeValidator and SCOPE_VIOLATION audit events (lines 170-183)"

      - strength: "Excellent requirements traceability"
        evidence: "User story (US-007) linked to 14 specific test scenarios across 5 acceptance criteria (lines 113-164)"

      - strength: "Thorough quick win analysis with viable alternatives evaluated"
        evidence: "Three alternatives properly evaluated and rejected with clear reasoning (lines 224-238)"

      - strength: "Clear measurement plan with phased validation"
        evidence: "Two-phase measurement approach (post-implementation + production) with concrete metrics (lines 361-382)"

      - strength: "Realistic constraint identification"
        evidence: "Technical, compatibility, and operational constraints properly documented (lines 271-287)"

    critiques:
      - severity: LOW
        category: measurement_methodology
        issue: "Secondary metric 'prompts_with_boundary_rules' uses percentage but baseline shows absolute 0"
        impact: "Minor inconsistency - could confuse whether 0% or 0 count is the baseline"
        location: "lines 186-190"
        recommendation: >
          Clarify baseline as "0% (0 of N prompts)" to show denominator. Example:
          "current: 0% (0/50 prompts analyzed)" - this makes the measurement method
          more explicit and reproducible.

      - severity: LOW
        category: risk_mitigation
        issue: "Git availability risk mitigation is generic without implementation details"
        impact: "Roadmap phase may need to specify exact error handling approach"
        location: "lines 320-321"
        recommendation: >
          Enhance mitigation with specific approach: "Use subprocess.run with
          capture_output=True, timeout=5s, check for CalledProcessError,
          log warning to audit trail, continue step execution."

      - severity: LOW
        category: evidence_quality
        issue: "Step file scope field existence verified via 'test fixtures' but production usage unclear"
        impact: "Risk item acknowledges this (line 317) but baseline doesn't quantify current scope field population"
        location: "lines 46-48, 309-313"
        recommendation: >
          Add measurement: "Analyzed X production step files: Y have scope.target_files
          populated (Z%), A have scope.allowed_patterns populated (B%)." This would
          strengthen the brownfield assessment and inform migration strategy.

    positive_observations:
      - observation: "Exceptional brownfield analysis"
        detail: >
          The artifact correctly identifies that infrastructure exists but lacks the
          critical middle layer. This prevents false starts where infrastructure might
          be rebuilt unnecessarily. Lines 78-85 clearly articulate why existing
          capabilities are insufficient.

      - observation: "Business value clearly articulated"
        detail: >
          Priya's pain point (scope creep causing merge conflicts and release delays)
          directly maps to 14 test scenarios covering 5 acceptance criteria. The
          baseline demonstrates clear understanding of stakeholder needs.

      - observation: "No-quick-wins analysis is honest and justified"
        detail: >
          Lines 209-243 correctly identify that partial implementation would not
          deliver value. This prevents scope reduction that would waste effort without
          solving Priya's problem. The interdependence analysis is sound.

      - observation: "Measurement baseline uses absence as evidence"
        detail: >
          Baseline value of 0 is measured via code inspection proving no ScopeValidator
          exists and no SCOPE_VIOLATION events are generated. This is a valid and
          reproducible measurement technique for "feature doesn't exist" scenarios.

    recommendations_for_roadmap:
      - priority: HIGH
        recommendation: >
          First roadmap task should verify scope field population across existing step
          files (addresses LOW severity critique #3). This discovery may influence
          whether graceful degradation logic is needed or if all files can be assumed
          to have scope populated.

      - priority: MEDIUM
        recommendation: >
          Include git error handling implementation details in ScopeValidator task
          (addresses LOW severity critique #2). Specify subprocess timeout, error
          types to catch, and audit log message format for git failures.

      - priority: LOW
        recommendation: >
          Roadmap should include task to measure prompts_with_boundary_rules baseline
          with denominator (addresses LOW severity critique #1). Quick grep of recent
          audit logs or orchestrator invocations would provide N for "0 of N" baseline.

    approval_justification: >
      The baseline artifact meets all quality standards for feature development:

      1. METRIC ACCURACY: Baseline value of 0 is correctly measured via absence of
         ScopeValidator component and SCOPE_VIOLATION audit events. Measurement method
         is reproducible (code inspection + audit log query).

      2. BASELINE VALIDITY: Current state accurately captured through detailed code
         references (validator.py:66, orchestrator.py:374). The "brownfield with
         infrastructure but no enforcement" assessment is precise and evidence-backed.

      3. MEASUREMENT METHODOLOGY: Two-phase measurement plan (post-implementation +
         production) with clear methods (pytest for test pass rate, audit log queries
         for violations). Reproducible and sound.

      4. TARGET SETTING: Target of 100% prompts with boundary rules is realistic given
         existing validation infrastructure. Success criteria are measurable (14/14
         tests pass, SCOPE_VIOLATION events appear in audit log).

      5. EVIDENCE QUALITY: Requirements sourced from validated user story (US-007) with
         14 test scenarios in test_us007_boundary_rules.py. Code references are precise
         with line numbers. Quick win analysis evaluates 3 alternatives.

      6. REQUIREMENTS SOURCE: Clear origin (US-007, Priya's scope creep problem) with
         acceptance criteria validation via 14 test scenarios. Business value articulated.

      The three LOW severity critiques are minor enhancements that do not block roadmap
      creation. They are addressable during roadmap execution without requiring baseline
      revision.

    decision: >
      APPROVED - Proceed to roadmap creation. This baseline provides a solid foundation
      for Outside-In TDD implementation. The comprehensive analysis, accurate measurements,
      and thorough justification demonstrate readiness for DEVELOP wave execution.

      The artifact successfully establishes the "unprotected" state baseline (zero scope
      enforcement) and defines clear success criteria (14/14 tests pass, 100% prompts
      with boundary rules, SCOPE_VIOLATION audit events). No blocking issues identified.
