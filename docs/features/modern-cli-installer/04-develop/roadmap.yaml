# Implementation Roadmap: modern-cli-installer
# Epic: modern_CLI_installer
# Solution Architect: Morgan
# Created: 2026-02-01
# Schema Version: 2.0

project:
  id: "modern-cli-installer"
  name: "Modern CLI Installer"
  goal: "Complete build -> install -> release pipeline for nWave framework with three interconnected journeys"
  methodology: "standard"
  schema_version: "2.0"
  created_at: "2026-02-01T00:00:00Z"

  journeys:
    - id: "J1"
      name: "forge:build-local-candidate"
      description: "Build pipx-compatible wheel with semantic versioning"
    - id: "J2"
      name: "forge:install-local-candidate"
      description: "Install and validate local wheel before release"
    - id: "J3"
      name: "install-nwave"
      description: "First-time PyPI installation for end users"

tdd_phases:
  - PREPARE
  - RED_ACCEPTANCE
  - RED_UNIT
  - GREEN
  - REVIEW
  - REFACTOR_CONTINUOUS
  - COMMIT

execution_config:
  context_extraction_method: "from_roadmap"
  status_tracking_file: "execution-log.yaml"
  token_budget_per_step: 5000
  acceptance_test_location: "docs/features/modern-cli-installer/03-distill"

implicit_prerequisites:
  runtime:
    - "Python 3.10+ installed and available as python3"
    - "pipx installed and on PATH"
    - "git installed with repository initialized"
  filesystem:
    - "Write access to ~/.claude/ directory"
    - "Write access to project dist/ directory"
  network:
    - "Internet access for PyPI/TestPyPI operations (CI only)"

implementation_scope:
  source_directories:
    - "nWave/core/installer/"
    - "nWave/infrastructure/installer/"
    - "nWave/cli/"
    - "nWave/core/versioning/"
  test_directories:
    - "tests/installer/"
    - "tests/cli/"
  excluded_patterns:
    - "__init__.py"
    - "__pycache__/**"
    - "*.pyc"

# ==============================================================================
# PHASE 00: SPRINT 0 PREREQUISITES
# ==============================================================================

phases:
  - id: "00"
    name: "Sprint 0 Prerequisites"
    description: "Platform infrastructure required before DEVELOP can begin"
    default_agent: "software-crafter"
    default_deps_strategy: "sequential"
    type: "infrastructure"
    notes: |
      These are blocking prerequisites identified in platform-readiness-review.md.
      Must complete before Phase 01 can begin.
    steps:
      - id: "00-01"
        name: "Create pyproject.toml with package configuration"
        type: "infrastructure"
        user_stories: []
        criteria: |
          - pyproject.toml exists at repository root
          - [build-system] configured with setuptools>=61.0
          - [project] section with name="nwave", version="0.0.0"
          - [project.scripts] with nw="nwave.cli:main" entry point
          - Dependencies declared: click, rich, pyyaml
          - requires-python = ">=3.10"
          - python -m build succeeds
          - twine check dist/*.whl passes
        dependencies: []
        estimated_hours: 2

      - id: "00-02"
        name: "Configure PyPI secrets in GitHub"
        type: "infrastructure"
        user_stories: []
        criteria: |
          - PYPI_API_TOKEN secret configured in GitHub repository
          - TEST_PYPI_API_TOKEN secret configured in GitHub repository
          - Secrets validated with test upload to TestPyPI
        dependencies: ["00-01"]
        estimated_hours: 1

      - id: "00-03"
        name: "Add TestPyPI publishing workflow to CI"
        type: "infrastructure"
        user_stories: []
        criteria: |
          - PR-level TestPyPI validation workflow added
          - Wheel builds on PR
          - Publishes to TestPyPI with unique dev version
          - E2E install test validates pipx install from TestPyPI
        dependencies: ["00-01", "00-02"]
        estimated_hours: 3

      - id: "00-04"
        name: "Add version sync quality gate to CI"
        type: "infrastructure"
        user_stories: []
        criteria: |
          - CI validates agent spec versions match pyproject.toml
          - Prevents version drift between components
          - Blocks PR on version mismatch
        dependencies: ["00-01"]
        estimated_hours: 2

      - id: "00-05"
        name: "Create test directory structure and pytest configuration"
        type: "infrastructure"
        user_stories: []
        criteria: |
          - tests/installer/ directory exists
          - tests/cli/ directory exists
          - pytest.ini or pyproject.toml [tool.pytest] configured
          - conftest.py with common fixtures for port mocking
          - Test dependencies added to pyproject.toml: pytest, pytest-bdd, pytest-cov
        dependencies: ["00-01"]
        estimated_hours: 1

# ==============================================================================
# PHASE 01: INFRASTRUCTURE - Shared Frameworks
# ==============================================================================

  - id: "01"
    name: "Infrastructure - Shared Frameworks"
    description: "Pre-flight check framework, Doctor health check framework, and shared artifact registry"
    default_agent: "software-crafter"
    default_deps_strategy: "sequential"
    notes: |
      Stories US-001 through US-005. These form the foundation for all three journeys.
      Hexagonal architecture with ports/adapters pattern.
    steps:
      - id: "01-01"
        name: "Create CheckResult domain object and CheckSeverity enum"
        user_stories: ["US-001"]
        scenario: "journey_1_build.feature::Pre-flight check validates Python version"
        criteria: |
          - CheckResult dataclass exists in nWave/core/installer/domain/check_result.py
          - Properties: id, name, passed, severity, message, remediation, fixable, fix_command
          - CheckSeverity enum with BLOCKING and WARNING values
          - Immutable (frozen=True dataclass)
          - Unit tests validate creation and equality
        dependencies: ["00-01"]
        estimated_hours: 2

      - id: "01-02"
        name: "Create CheckRegistry and CheckExecutor for pre-flight checks"
        user_stories: ["US-001"]
        scenario: "journey_1_build.feature::Successful local build with all checks passing"
        criteria: |
          - CheckRegistry class with register() and get_checks_for_journey() methods
          - CheckExecutor runs all registered checks for a journey
          - Returns list of CheckResult objects
          - Checks run in parallel where possible
          - Journey identifiers: "build", "install-local", "install-pypi"
        dependencies: ["01-01"]
        estimated_hours: 3

      - id: "01-03"
        name: "Create core pre-flight checks (python_version, pipx_available, claude_dir_writable)"
        user_stories: ["US-001"]
        scenario: "horizontal_coherence.feature::Pre-flight table format identical across all three journeys"
        criteria: |
          - python_version check validates >=3.10
          - pipx_available check validates pipx is installed
          - claude_dir_writable check validates ~/.claude permissions
          - All checks return CheckResult with consistent format
          - Display format: "{check_name} [check] {details}" for pass
          - Display format: "{check_name} [x] {error}" for fail
        dependencies: ["01-02"]
        estimated_hours: 3

      - id: "01-04"
        name: "Create HealthStatus enum and HealthChecker for doctor framework"
        user_stories: ["US-002"]
        scenario: "journey_2_install.feature::Doctor verification matches install-nwave pattern"
        criteria: |
          - HealthStatus enum with HEALTHY, DEGRADED, UNHEALTHY values
          - HealthChecker runs all health checks and determines overall status
          - HEALTHY: all critical checks pass
          - DEGRADED: critical pass but warnings exist
          - UNHEALTHY: one or more critical failures
          - Returns structured health report
        dependencies: ["01-01"]
        estimated_hours: 3

      - id: "01-05"
        name: "Create doctor health checks (core_installation, file counts, config, permissions, version)"
        user_stories: ["US-002"]
        scenario: "horizontal_coherence.feature::Doctor check order identical between local and PyPI install"
        criteria: |
          - Seven checks in fixed order: core_installation, agent_files, command_files, template_files, config_valid, permissions, version_match
          - File count checks compare against expected manifest counts
          - Config check validates nwave.yaml parses correctly
          - Version check compares nw --version output against expected
          - Consistent display format across Journey 2 and Journey 3
        dependencies: ["01-04"]
        estimated_hours: 4

      - id: "01-06"
        name: "Create ArtifactRegistry for shared artifact values"
        user_stories: ["US-003"]
        scenario: "horizontal_coherence.feature::Artifacts flow correctly from build to install to doctor"
        criteria: |
          - ArtifactRegistry provides get_version(), get_candidate_version(), get_wheel_path()
          - get_counts() returns ArtifactCounts with agent_count, command_count, template_count
          - Version read from pyproject.toml
          - Wheel path derived from candidate version
          - Consistent values across all journey steps
        dependencies: ["01-01"]
        estimated_hours: 3

      - id: "01-07"
        name: "Create ConfigPort and ConfigAdapter for installer configuration"
        user_stories: ["US-004"]
        scenario: "journey_3_pypi.feature::Install path resolution uses default when no override"
        criteria: |
          - ConfigPort interface with resolve_install_path(), get_env_var(), load_config()
          - ConfigAdapter implements port with real environment/filesystem
          - Resolution order: NWAVE_INSTALL_PATH env -> config file -> default ~/.claude/agents/nw/
          - CI mode detection via CI, GITHUB_ACTIONS, GITLAB_CI, JENKINS_URL
          - Path expansion for ~ handled correctly
        dependencies: []
        estimated_hours: 3

      - id: "01-08"
        name: "Create URL configuration management"
        user_stories: ["US-005"]
        scenario: "N/A - infrastructure support"
        criteria: |
          - URLs loaded from nWave/data/config/urls.yaml
          - docs.base, docs.getting_started, docs.api, docs.troubleshooting configured
          - repo.github, repo.issues, repo.releases configured
          - package.pypi configured
          - support.community, support.bug_report configured
          - All display URLs read from config, not hardcoded
        dependencies: []
        estimated_hours: 2

# ==============================================================================
# PHASE 02: JOURNEY 1 - Build Local Candidate
# ==============================================================================

  - id: "02"
    name: "Journey 1 - Build Local Candidate"
    description: "forge:build-local-candidate journey implementation"
    default_agent: "software-crafter"
    default_deps_strategy: "sequential"
    notes: |
      Stories US-010 through US-019. Build pipx-compatible wheel with semantic versioning.
      Emotional arc: Focused -> Confident -> Accomplished
    steps:
      - id: "02-01"
        name: "Create build-specific pre-flight checks"
        user_stories: ["US-010"]
        scenario: "journey_1_build.feature::Pre-flight check validates build package"
        criteria: |
          - build_package check validates python -m build --version succeeds
          - pyproject_toml_exists check validates file exists
          - pyproject_toml_valid check validates TOML parses without error
          - source_directory check validates nWave/ exists
          - dist_directory check validates dist/ is writable (creates if needed)
          - All checks registered for "build" journey
        dependencies: ["01-03"]
        estimated_hours: 3

      - id: "02-02"
        name: "Create GitPort and GitAdapter for commit analysis"
        user_stories: ["US-011"]
        scenario: "journey_1_build.feature::Version bump from conventional commits - MINOR"
        criteria: |
          - GitPort interface with get_commits_since_tag(), get_last_tag()
          - GitAdapter implements using git CLI
          - Returns list of commit messages since last tag
          - Handles case where no tags exist
          - Handles case where no commits since tag
        dependencies: []
        estimated_hours: 2

      - id: "02-03"
        name: "Create CandidateVersion domain object"
        user_stories: ["US-011", "US-017"]
        scenario: "journey_1_build.feature::Daily sequence increments on same day"
        criteria: |
          - CandidateVersion value object with base_version, date, sequence
          - Format: M.m.p-dev-YYYYMMDD-seq (e.g., 1.3.0-dev-20260201-001)
          - PEP 440 wheel format: M.m.p.devYYYYMMDDseq (e.g., 1.3.0.dev20260201001)
          - Factory method CandidateVersion.create()
          - Parser method CandidateVersion.parse()
          - Sequence tracking persists per date
        dependencies: ["01-01"]
        estimated_hours: 3

      - id: "02-04"
        name: "Create VersionBumpService for conventional commit analysis"
        user_stories: ["US-011", "US-016"]
        scenario: "journey_1_build.feature::Version bump detects breaking changes - MAJOR"
        criteria: |
          - VersionBumpService analyzes commits since last tag
          - BREAKING CHANGE or ! suffix -> MAJOR bump
          - feat: prefix -> MINOR bump
          - fix: prefix -> PATCH bump
          - --force-version flag overrides auto-calculation
          - Force version must be > current version
          - Warns if no commits since last tag
        dependencies: ["02-02", "02-03"]
        estimated_hours: 4

      - id: "02-05"
        name: "Create BuildPort and BuildAdapter for wheel building"
        user_stories: ["US-012"]
        scenario: "journey_1_build.feature::Build process shows progress phases"
        criteria: |
          - BuildPort interface with clean_dist(), build_wheel()
          - BuildAdapter wraps python -m build
          - Three phases: clean, process, build
          - Returns BuildResult with wheel_path, file_count, duration
          - Captures and reports backend errors with suggested fixes
        dependencies: []
        estimated_hours: 3

      - id: "02-06"
        name: "Create wheel validation service"
        user_stories: ["US-013"]
        scenario: "journey_1_build.feature::Wheel validation checks all required aspects"
        criteria: |
          - Validates wheel file format is correct
          - Validates pyproject.toml metadata is bundled
          - Validates nw CLI entry point is defined
          - Counts agents, commands, templates bundled in wheel
          - Validates pipx compatibility
          - Fails fast on first critical issue
          - Returns WheelValidationResult with all check results
        dependencies: ["01-06"]
        estimated_hours: 4

      - id: "02-07"
        name: "Create BuildService orchestrating build journey"
        user_stories: ["US-010", "US-011", "US-012", "US-013", "US-014"]
        scenario: "journey_1_build.feature::Successful local build with all checks passing"
        criteria: |
          - BuildService orchestrates: preflight -> version bump -> build -> validate -> summary
          - Uses PreflightService for checks
          - Uses VersionBumpService for version calculation
          - Uses BuildAdapter for wheel building
          - Uses wheel validation service
          - Returns complete BuildResult with all artifacts
        dependencies: ["02-01", "02-04", "02-05", "02-06"]
        estimated_hours: 4

      - id: "02-08"
        name: "Create forge:build CLI command"
        user_stories: ["US-010", "US-014", "US-015", "US-018"]
        scenario: "journey_1_build.feature::Build works in non-interactive CI mode"
        criteria: |
          - CLI entry point forge:build-local-candidate or nw forge build
          - Displays pre-flight table with consistent format
          - Displays version bump analysis
          - Displays build progress phases
          - Displays success summary with "FORGE: BUILD COMPLETE"
          - Prompts "Install locally now? [Y/n]" (skipped in CI mode)
          - --no-prompt flag skips install prompt
          - --install flag triggers auto-install
          - --force-version flag for version override
          - CI=true suppresses prompts, returns exit codes
        dependencies: ["02-07"]
        estimated_hours: 4

      - id: "02-09"
        name: "Create auto-repair for missing build package"
        user_stories: ["US-019"]
        scenario: "journey_1_build.feature::Developer accepts auto-repair for missing build package"
        criteria: |
          - build_package check marked as fixable=True
          - fix_command="pip install build"
          - Prompt asks "Install it now? [Y/n]"
          - On Y: runs pip install build, resumes pre-flight
          - On n: aborts with manual instructions
          - Shows spinner during install
          - Shows success message with installed version
        dependencies: ["02-01", "02-08"]
        estimated_hours: 2

# ==============================================================================
# PHASE 03: JOURNEY 2 - Install Local Candidate
# ==============================================================================

  - id: "03"
    name: "Journey 2 - Install Local Candidate"
    description: "forge:install-local-candidate journey implementation"
    default_agent: "software-crafter"
    default_deps_strategy: "sequential"
    notes: |
      Stories US-020 through US-029. Install and validate local wheel before release.
      Emotional arc: Focused -> Trust -> Celebratory
    steps:
      - id: "03-01"
        name: "Create install-specific pre-flight checks"
        user_stories: ["US-020"]
        scenario: "journey_2_install.feature::Pre-flight validates wheel exists"
        criteria: |
          - wheel_exists check validates .whl file in dist/
          - wheel_format check validates wheel filename format
          - pipx_isolation check validates pipx can create isolated env
          - install_path_resolved check confirms target path
          - All checks registered for "install-local" journey
          - wheel_exists marked fixable with chain to build
        dependencies: ["01-03"]
        estimated_hours: 3

      - id: "03-02"
        name: "Create PipxPort and PipxAdapter"
        user_stories: ["US-022"]
        scenario: "journey_2_install.feature::Install uses pipx with force flag"
        criteria: |
          - PipxPort interface with is_available(), install(), uninstall(), list_packages()
          - PipxAdapter implements using pipx CLI
          - install() accepts wheel_path and force flag
          - Returns InstallResult with success, version, path
          - Handles uninstall of previous version before install
        dependencies: []
        estimated_hours: 3

      - id: "03-03"
        name: "Create release readiness validation service"
        user_stories: ["US-021"]
        scenario: "journey_2_install.feature::Release readiness shows all PyPI requirements met"
        criteria: |
          - Runs twine check on wheel (blocking)
          - Validates metadata completeness: name, version, description, author, license
          - Validates entry points: nw CLI defined
          - Validates CHANGELOG entry exists (warning, not blocking)
          - Validates PEP 440 version format
          - Validates LICENSE and README bundled
          - Returns "READY FOR PYPI" or failure status
        dependencies: ["02-06"]
        estimated_hours: 4

      - id: "03-04"
        name: "Create BackupPort and BackupAdapter"
        user_stories: ["US-039"]
        scenario: "journey_3_pypi.feature::Backup is created before installation on upgrade"
        criteria: |
          - BackupPort interface with create_backup(), restore_backup(), list_backups()
          - BackupAdapter implements using filesystem operations
          - Backup path: ~/.claude/backups/nwave-YYYYMMDD-HHMMSS/
          - Includes agents, commands, templates, manifest
          - cleanup_old_backups() retains configurable count
        dependencies: []
        estimated_hours: 3

      - id: "03-05a"
        name: "Create InstallService core orchestration (preflight -> readiness -> backup -> install)"
        user_stories: ["US-020", "US-021", "US-022"]
        scenario: "journey_2_install.feature::Successful candidate installation with all checks passing"
        criteria: |
          - InstallService orchestrates first four phases: preflight -> readiness -> backup -> install
          - Uses PreflightService for install-specific checks
          - Uses release readiness service for PyPI validation
          - Uses BackupAdapter for backup creation before install
          - Uses PipxAdapter for wheel installation with force flag
          - Returns intermediate InstallResult with install status (pending verification)
          - Handles install failures with clear error messages
        dependencies: ["03-01", "03-02", "03-03", "03-04"]
        estimated_hours: 3

      - id: "03-05b"
        name: "Create InstallService verification orchestration (doctor verification -> result aggregation)"
        user_stories: ["US-023"]
        scenario: "journey_2_install.feature::Doctor verification matches install-nwave pattern"
        criteria: |
          - InstallService completes orchestration with verification phase
          - Uses DoctorService for post-install health verification
          - Aggregates results from all phases into complete InstallResult
          - Returns complete InstallResult with health status (HEALTHY/DEGRADED/UNHEALTHY)
          - Maps doctor results to final install outcome
          - Provides structured data for release report generation
        dependencies: ["03-05a", "01-05"]
        estimated_hours: 2

      - id: "03-06"
        name: "Create release report generator"
        user_stories: ["US-024"]
        scenario: "journey_2_install.feature::Release report provides complete summary"
        criteria: |
          - Header: "FORGE: CANDIDATE INSTALLED"
          - Release summary: version, branch, build timestamp, install timestamp
          - Install manifest: agent count, command count, template count, install path
          - Release readiness: summary of all checks
          - Test checklist: restart Claude, /nw:version, /nw:help, test agent, nw doctor
          - Supports JSON output for CI/CD
          - Supports file output via --output flag
        dependencies: ["03-05b"]
        estimated_hours: 3

      - id: "03-07"
        name: "Create forge:install CLI command"
        user_stories: ["US-020", "US-024", "US-027", "US-028", "US-029"]
        scenario: "journey_2_install.feature::Install works in non-interactive CI mode"
        criteria: |
          - CLI entry point forge:install-local-candidate or nw forge install
          - Displays pre-flight table
          - Displays release readiness validation
          - Displays install progress phases
          - Displays doctor verification
          - Displays release report
          - --json flag outputs JSON instead of TUI
          - --output flag writes report to file
          - --strict flag elevates warnings to errors
          - CI=true auto-selects newest wheel, suppresses prompts
        dependencies: ["03-05b", "03-06"]
        estimated_hours: 4

      - id: "03-08"
        name: "Create auto-chain to build when no wheel found"
        user_stories: ["US-025"]
        scenario: "journey_2_install.feature::Developer accepts auto-chain to build-local"
        criteria: |
          - wheel_exists check detects empty dist/ or no .whl files
          - Prompt asks "Run forge:build-local now? [Y/n]"
          - On Y: runs forge:build-local, then resumes install
          - On n: aborts with manual build command
          - Message shows "Resuming install-local-candidate..."
        dependencies: ["03-01", "03-07", "02-08"]
        estimated_hours: 2

      - id: "03-09"
        name: "Create multiple wheel selection prompt"
        user_stories: ["US-026"]
        scenario: "journey_2_install.feature::Developer selects wheel from multiple options"
        criteria: |
          - Detects multiple .whl files in dist/
          - Shows numbered list sorted by modification time (newest first)
          - Prompt asks "Select wheel [1-N, or 'c' to cancel]:"
          - Validates input is valid number or 'c'
          - CI mode auto-selects newest without prompt
        dependencies: ["03-07"]
        estimated_hours: 2

# ==============================================================================
# PHASE 04: JOURNEY 3 - PyPI Install
# ==============================================================================

  - id: "04"
    name: "Journey 3 - PyPI Install"
    description: "install-nwave journey for first-time PyPI installation"
    default_agent: "software-crafter"
    default_deps_strategy: "sequential"
    notes: |
      Stories US-030 through US-039. First-time PyPI installation for end users.
      Emotional arc: Excited -> Confident -> Delighted
    steps:
      - id: "04-01"
        name: "Create PyPI-specific pre-flight checks"
        user_stories: ["US-030", "US-031"]
        scenario: "journey_3_pypi.feature::Pre-flight check validates Python version"
        criteria: |
          - Reuses core checks: python_version, pipx_available, claude_dir_writable
          - Adds claude_code_installed check (warning, not blocking)
          - All checks registered for "install-pypi" journey
          - Pre-flight output shows resolved install path
        dependencies: ["01-03"]
        estimated_hours: 2

      - id: "04-02"
        name: "Create upgrade detection service"
        user_stories: ["US-041"]
        scenario: "journey_3_pypi.feature::Upgrade from older version"
        criteria: |
          - Detects existing nWave installation at install_path
          - Reads installed version from manifest.yaml or nwave.yaml
          - Compares with incoming version using semver
          - Returns upgrade path: FRESH_INSTALL, UPGRADE, REINSTALL, DOWNGRADE
          - FRESH_INSTALL: no backup, proceed directly
          - UPGRADE: create backup, show "Upgrading from X to Y"
          - REINSTALL: prompt confirmation (skipped in CI)
          - DOWNGRADE: warn and require confirmation
        dependencies: ["01-07", "03-04"]
        estimated_hours: 4

      - id: "04-03"
        name: "Create framework installation progress display"
        user_stories: ["US-032"]
        scenario: "journey_3_pypi.feature::Framework installation shows progress bars"
        criteria: |
          - Spinner for "Checking source files"
          - Progress bar for "Building distribution"
          - Per-component progress: Agents, Commands, Templates
          - Each component shows count and checkmark when complete
          - Validation table at end showing all counts
          - Final status "Validation: PASSED"
        dependencies: ["03-05b"]
        estimated_hours: 3

      - id: "04-04"
        name: "Create welcome and celebration display"
        user_stories: ["US-034", "US-035"]
        scenario: "journey_3_pypi.feature::Welcome message displays celebration"
        criteria: |
          - nWave ASCII logo displayed
          - Message: "nWave v{version} installed successfully!"
          - Message: "Your Claude is now powered by nWave"
          - Restart instruction in highlighted box
          - Next steps list: 1. Restart Claude Code, 2. /nw:version, 3. /nw:help
          - Documentation URL from urls.yaml
          - Suppressed in CI mode
        dependencies: ["01-08"]
        estimated_hours: 2

      - id: "04-05"
        name: "Create nw setup command for post-install agent setup"
        user_stories: ["US-032"]
        scenario: "journey_3_pypi.feature::Successful first-time installation"
        criteria: |
          - nw setup command copies agents to install_path
          - Auto-triggered on first run after pipx install
          - Can be run manually for repair/reinstall
          - Creates ~/.claude/agents/nw/ directory if needed
          - Copies agents, commands, templates from package
          - Creates manifest.json with version and counts
          - Uses FileSystemPort for all directory and file operations (not direct os/shutil calls)
          - FileSystemPort enables test isolation without actual filesystem operations
        dependencies: ["03-05b"]
        estimated_hours: 4

      - id: "04-06"
        name: "Create nw doctor CLI command"
        user_stories: ["US-033"]
        scenario: "journey_3_pypi.feature::Doctor runs after successful install"
        criteria: |
          - nw doctor command runs health verification
          - Displays doctor table with all seven checks
          - Shows HEALTHY/DEGRADED/UNHEALTHY status
          - --json flag for machine-readable output
          - Counts match installation validation
          - Used by both Journey 2 and Journey 3
        dependencies: ["01-05"]
        estimated_hours: 3

      - id: "04-07"
        name: "Create nw version command"
        user_stories: ["US-036"]
        scenario: "journey_3_pypi.feature::Verify installation in Claude Code"
        criteria: |
          - nw --version shows "nWave Framework v{version}"
          - Shows install path: "Installed: {path}"
          - Shows counts: "Agents: N | Commands: N | Templates: N"
          - Shows "All systems operational" if healthy
          - Counts match doctor output
        dependencies: ["01-06"]
        estimated_hours: 2

      - id: "04-08"
        name: "Create install-nwave CI mode support"
        user_stories: ["US-038"]
        scenario: "journey_3_pypi.feature::Installation works in non-interactive CI mode"
        criteria: |
          - Detects CI environment variables
          - Suppresses ASCII logo in CI
          - Suppresses interactive prompts
          - Returns exit code 0 on success, non-zero on failure
          - --format json for machine-readable output
          - JSON includes: success, version, counts
        dependencies: ["04-04", "04-05"]
        estimated_hours: 2

# ==============================================================================
# PHASE 05: CROSS-CUTTING CONCERNS
# ==============================================================================

  - id: "05"
    name: "Cross-Cutting Concerns"
    description: "Rollback, upgrade detection, and integration checkpoints"
    default_agent: "software-crafter"
    default_deps_strategy: "sequential"
    notes: |
      Stories US-040 and US-041. These apply across all journeys.
    steps:
      - id: "05-01"
        name: "Create RollbackService for automatic and manual rollback"
        user_stories: ["US-040"]
        scenario: "journey_3_pypi.feature::Automatic rollback on installation failure"
        criteria: |
          - RollbackService.auto_rollback() triggers on install failure
          - Restores from most recent backup
          - Cleans partial install files before restore
          - RollbackService.manual_rollback() for nw rollback command
          - Lists available backups with timestamps
          - User selects backup to restore
          - Runs nw doctor after restore to verify
          - Clear message: "Installation failed. Previous version restored."
        dependencies: ["03-04"]
        estimated_hours: 4

      - id: "05-02"
        name: "Create nw rollback CLI command"
        user_stories: ["US-040"]
        scenario: "journey_3_pypi.feature::Manual rollback command"
        criteria: |
          - nw rollback lists available backups
          - Shows backup date, time, and version
          - User selects backup by number
          - Restores selected backup
          - Runs nw doctor to confirm
          - Shows "Rolled back to backup from {timestamp}"
          - Error if no backups available
        dependencies: ["05-01"]
        estimated_hours: 2

      - id: "05-03"
        name: "Create integration checkpoint display"
        user_stories: ["US-003"]
        scenario: "horizontal_coherence.feature::Integration checkpoint displays at build-to-install transition"
        criteria: |
          - Checkpoint box displays at journey transitions
          - Header: "INTEGRATION CHECKPOINT"
          - Shows "version matches build" with checkmark
          - Shows "wheel path verified" with checkmark
          - Shows "artifact counts consistent" with checkmark
          - Blocks on mismatch with error details
        dependencies: ["01-06"]
        estimated_hours: 2

      - id: "05-04"
        name: "Integrate upgrade detection into install flows"
        user_stories: ["US-041"]
        scenario: "journey_3_pypi.feature::Reinstall same version prompts confirmation"
        criteria: |
          - InstallService uses upgrade detection before install
          - FRESH_INSTALL: skip backup, show "(fresh install)"
          - UPGRADE: create backup, show "Upgrading from X to Y"
          - REINSTALL: prompt confirmation, backup on Y
          - DOWNGRADE: warn, require confirmation, backup on Y
          - CI mode: auto-proceed for upgrade, skip prompts
        dependencies: ["04-02", "03-05b"]
        estimated_hours: 3

# ==============================================================================
# PHASE 06: HORIZONTAL COHERENCE AND E2E VALIDATION
# ==============================================================================

  - id: "06"
    name: "Horizontal Coherence and E2E Validation"
    description: "Cross-journey consistency validation and TestPyPI integration"
    default_agent: "software-crafter"
    default_deps_strategy: "sequential"
    notes: |
      Validates that all journeys produce consistent artifacts and displays.
      Includes TestPyPI PR-level validation.
    steps:
      - id: "06-01"
        name: "Validate pre-flight format consistency across journeys"
        user_stories: ["US-001"]
        scenario: "horizontal_coherence.feature::Pre-flight table format identical across all three journeys"
        criteria: |
          - Pre-flight table structure identical across all journeys
          - Column headers: "Check" and "Status"
          - Icons identical: [check] for pass, [x] for fail, [!] for warning
          - Python version check displays identically
          - Error formats identical across journeys
        dependencies: ["02-08", "03-07", "04-08"]
        estimated_hours: 2

      - id: "06-02"
        name: "Validate doctor format consistency between Journey 2 and 3"
        user_stories: ["US-002"]
        scenario: "horizontal_coherence.feature::Doctor output format identical between Journey 2 and Journey 3"
        criteria: |
          - Doctor table format identical
          - Check order identical (7 checks in same sequence)
          - Status terminology identical (HEALTHY, DEGRADED, UNHEALTHY)
          - Component display format identical
          - Version display format identical
          - Install path display format identical
        dependencies: ["03-07", "04-06"]
        estimated_hours: 2

      - id: "06-03"
        name: "Validate artifact flow from build to install to doctor"
        user_stories: ["US-003"]
        scenario: "horizontal_coherence.feature::Version string format consistent through build-install flow"
        criteria: |
          - Version identical in: build summary, install pre-flight, release readiness, doctor, report
          - Wheel path identical in: pre-flight, readiness, install command, report
          - Counts identical in: wheel validation, doctor, release report
          - No artifact value drift between steps
        dependencies: ["05-03"]
        estimated_hours: 2

      - id: "06-04"
        name: "Create TestPyPI E2E validation test"
        user_stories: []
        scenario: "testpypi_coherence.feature::TestPyPI install produces identical result to local install"
        type: "infrastructure"
        criteria: |
          - E2E test validates pipx install from TestPyPI
          - Fresh environment with pipx installed
          - Installs version from TestPyPI index
          - Runs nw doctor, validates HEALTHY
          - Validates version matches, counts match
          - Runs as part of PR CI pipeline
        dependencies: ["04-08"]
        estimated_hours: 4

      - id: "06-05"
        name: "Create TestPyPI CI quality gate"
        user_stories: []
        scenario: "testpypi_coherence.feature::PR cannot merge without TestPyPI validation passing"
        type: "infrastructure"
        criteria: |
          - CI gate requires: wheel_build, twine_check, testpypi_upload, testpypi_install, doctor_healthy
          - PR blocked if any check fails
          - Clear failure diagnostics with failed step and suggested fix
          - Unique dev version per PR prevents collision
          - Retries with backoff for transient failures
        dependencies: ["06-04"]
        estimated_hours: 3

# ==============================================================================
# PHASE 09: UNIFIED INSTALL PIPELINE INTEGRATION
# ==============================================================================

  - id: "09"
    name: "Unified Install Pipeline Integration"
    description: "Integrate IDE bundle build, asset deployment, and deployment validation into forge flow"
    default_agent: "software-crafter"
    default_deps_strategy: "sequential"
    notes: |
      Implements Morgan's integration architecture (APPROVED by Eclipse).
      Walking skeleton approach: simplest service first, integration last.
      All unit/integration tests written by Quinn in DISTILL wave.
      Tests use NotImplementedError pattern - implementation makes them GREEN.
      Architecture doc: docs/features/modern-cli-installer/02-design/unified-install-integration-architecture.md
    steps:
      - id: "09-01"
        name: "Create shared IDE bundle constants module"
        type: "infrastructure"
        user_stories: []
        scenario: "N/A - data-only constants module, no behavioral tests"
        criteria: |
          - ide_bundle_constants.py exists at src/crafter_ai/installer/domain/
          - EXPECTED_AGENT_COUNT = 30
          - EXPECTED_COMMAND_COUNT = 23
          - EXPECTED_TEMPLATE_COUNT = 17
          - EXPECTED_SCRIPT_COUNT = 4
          - EXPECTED_TEAM_COUNT = 0
          - EXPECTED_SCHEMA_VERSION = "v3.0"
          - EXPECTED_SCHEMA_PHASES = 7
          - Path constants: DEFAULT_SOURCE_DIR, DEFAULT_OUTPUT_DIR, DEFAULT_DEPLOY_TARGET
          - Subdirectory constants: AGENTS_SUBDIR, COMMANDS_SUBDIR, TEMPLATES_SUBDIR, SCRIPTS_SUBDIR
          - All tests that reference these counts import from this module
        dependencies: []
        estimated_hours: 1

      - id: "09-02"
        name: "Extend InMemoryFileSystemAdapter with copy_file method"
        type: "infrastructure"
        user_stories: []
        scenario: "N/A - test infrastructure extension"
        criteria: |
          - InMemoryFileSystemAdapter in tests/installer/conftest.py gains copy_file(src, dst) method
          - copy_file reads src content from in-memory store and writes to dst path
          - Raises FileNotFoundError if src does not exist in memory
          - Existing tests continue to pass unchanged
          - FileSystemPort protocol in production already defines copy_file (verified)
        dependencies: []
        estimated_hours: 1

      - id: "09-03"
        name: "Implement IdeBundleExistsCheck pre-flight check"
        user_stories: ["US-020"]
        scenario: "tests/installer/checks/test_deployment_checks.py (4 tests)"
        criteria: |
          - IdeBundleExistsCheck class at src/crafter_ai/installer/checks/ide_bundle_exists_check.py
          - Constructor accepts filesystem (FileSystemPort) and bundle_dir (Path)
          - execute() returns CheckResult with BLOCKING severity if bundle_dir missing or empty
          - execute() returns CheckResult with passed=True and agent/command counts in message if bundle exists
          - Message format includes counts for TUI display alignment
          - All 4 tests in test_deployment_checks.py pass GREEN
        dependencies: ["09-01", "09-02"]
        estimated_hours: 2

      - id: "09-04"
        name: "Implement IdeBundleBuildService"
        user_stories: ["US-012"]
        scenario: "tests/installer/services/test_ide_bundle_build_service.py (8 tests)"
        criteria: |
          - IdeBundleBuildService class at src/crafter_ai/installer/services/ide_bundle_build_service.py
          - Constructor accepts filesystem (FileSystemPort)
          - build(source_dir, output_dir) scans nWave/ source for agents, commands, templates, scripts
          - Copies files to output_dir with correct subdirectory structure
          - Returns immutable IdeBundleBuildResult with counts and success status
          - Handles missing source directory with clear error
          - Handles YAML parse warnings without failing build
          - Uses filesystem port primitives for tree copying (no shutil)
          - All 8 tests in test_ide_bundle_build_service.py pass GREEN
        dependencies: ["09-01", "09-02"]
        estimated_hours: 4

      - id: "09-05"
        name: "Implement AssetDeploymentService"
        user_stories: ["US-022"]
        scenario: "tests/installer/services/test_asset_deployment_service.py (8 tests)"
        criteria: |
          - AssetDeploymentService class at src/crafter_ai/installer/services/asset_deployment_service.py
          - Constructor accepts filesystem (FileSystemPort)
          - deploy(source_dir, target_dir) copies dist/ide/ contents to ~/.claude/ structure
          - Creates target subdirectories (agents/nw/, commands/nw/, templates/, scripts/)
          - Returns immutable AssetDeploymentResult with counts of deployed files per category
          - Handles missing source directory with clear error
          - Handles target directory creation if not exists
          - Uses filesystem port primitives for tree copying (no shutil)
          - All 8 tests in test_asset_deployment_service.py pass GREEN
        dependencies: ["09-01", "09-02"]
        estimated_hours: 3

      - id: "09-06"
        name: "Implement DeploymentValidationService"
        user_stories: ["US-023"]
        scenario: "tests/installer/services/test_deployment_validation_service.py (8 tests)"
        criteria: |
          - DeploymentValidationService class at src/crafter_ai/installer/services/deployment_validation_service.py
          - Constructor accepts filesystem (FileSystemPort)
          - validate(target_dir, expected_agents, expected_commands, expected_templates, expected_scripts) counts deployed files
          - Compares actual counts against expected counts
          - Writes manifest file to target_dir with validation results
          - Returns immutable DeploymentValidationResult with match status and per-category breakdown
          - Handles missing target directory gracefully
          - Reports specific mismatches (expected N agents, found M)
          - All 8 tests in test_deployment_validation_service.py pass GREEN
        dependencies: ["09-01", "09-02"]
        estimated_hours: 3

      - id: "09-07"
        name: "Integrate IdeBundleBuildService into BuildService"
        user_stories: ["US-012", "US-013"]
        scenario: "tests/installer/integration/test_unified_pipeline_integration.py (build-side tests)"
        criteria: |
          - BuildService constructor gains optional ide_bundle_build_service parameter (None default)
          - BuildService.execute() calls ide_bundle_build_service.build() after wheel validation when provided
          - BuildResult dataclass gains optional ide_bundle_result field (None default)
          - Build failure in IDE bundle step fails overall build with clear error
          - Skipping IDE bundle step when service not provided preserves backward compatibility
          - Existing BuildService tests continue to pass unchanged
          - Build-side integration tests in test_unified_pipeline_integration.py pass GREEN
        dependencies: ["09-04"]
        estimated_hours: 3

      - id: "09-08"
        name: "Integrate deployment services into InstallService"
        user_stories: ["US-022", "US-023"]
        scenario: "tests/installer/integration/test_unified_pipeline_integration.py (install-side tests)"
        criteria: |
          - InstallService constructor gains optional asset_deployment_service and deployment_validation_service parameters
          - InstallPhase enum gains ASSET_DEPLOYMENT and DEPLOYMENT_VALIDATION values
          - InstallService.install() calls asset_deployment_service.deploy() after pipx install when provided
          - InstallService.install() calls deployment_validation_service.validate() after deployment when provided
          - IdeBundleExistsCheck registered in install preflight when ide_bundle_dir provided
          - InstallResult extended with deployment and validation phase results
          - Skipping deployment steps when services not provided preserves backward compatibility
          - Existing InstallService tests continue to pass unchanged
          - Install-side integration tests in test_unified_pipeline_integration.py pass GREEN
        dependencies: ["09-03", "09-05", "09-06", "09-07"]
        estimated_hours: 4

  # ==========================================================================
  # PHASE 10: Full Installation Journey (Walking Skeleton Integration)
  # ==========================================================================
  # Connect backend services (Phase 09) to CLI rendering layer (forge_build.py,
  # forge_install.py) to implement Luna's complete TUI design with spinners.
  # Each step makes 1-2 walking skeleton tests pass (from 10 RED → 0 RED).
  #
  # Walking skeleton: tests/acceptance/forge_tui/test_walking_skeleton.py
  # Luna's design: docs/ux/modern-cli-installer/journey-forge-tui-visual.md
  # ==========================================================================

  - id: "10"
    name: "Full Installation Journey (Walking Skeleton Integration)"
    description: |
      Wire Phase 09 backend services into the forge CLI rendering layer and
      implement the 6 missing TUI sections from Luna's design. Makes all 10 RED
      walking skeleton tests pass by connecting BuildService/InstallService to
      the terminal output with proper spinners, component counts, and SBOM.
    user_stories: ["US-020", "US-021", "US-022", "US-023"]
    depends_on: ["09"]
    deliverables:
      - "IDE bundle build section in forge_build.py with spinner"
      - "Asset deployment section in forge_install.py with spinner"
      - "Deployment validation section with per-component checks"
      - "SBOM manifest dual-group format (CLI + IDE assets)"
      - "nWave brand in celebration, Getting started section"
      - "All 25 walking skeleton tests GREEN"
    steps:

      - id: "10-01"
        name: "Add IDE bundle build section to forge_build.py"
        scenario: "tests/acceptance/forge_tui/test_walking_skeleton.py::TestWalkingSkeletonBuildToInstall::test_ide_bundle_build_output"
        criteria: |
          - Wire IdeBundleBuildService into create_build_service() factory
          - Add section header: "⚙️ Building IDE bundle" after wheel validation
          - Add spinner: "⏳ Processing nWave assets..." during build
          - Spinner resolves to: "✅ IDE bundle built ({duration})"
          - Show detail lines: agent count, command count, team count
          - Show embed injection count if > 0
          - Show YAML warnings if any (with file names)
          - Walking skeleton test test_ide_bundle_build_output passes
        dependencies: ["09-04"]
        estimated_hours: 2

      - id: "10-02"
        name: "Add IDE bundle artifact line to build complete"
        scenario: "tests/acceptance/forge_tui/test_walking_skeleton.py::TestWalkingSkeletonBuildToInstall::test_build_complete_shows_two_artifacts"
        criteria: |
          - In build complete section, after wheel filename line
          - Add dim detail line: "IDE bundle: {agent_count} agents, {command_count} commands"
          - Extract counts from BuildResult.ide_bundle_result
          - Walking skeleton test test_build_complete_shows_two_artifacts passes
        dependencies: ["10-01"]
        estimated_hours: 1

      - id: "10-03"
        name: "Add asset deployment section to forge_install.py"
        scenario: "tests/acceptance/forge_tui/test_walking_skeleton.py::TestWalkingSkeletonBuildToInstall::test_asset_deployment_output"
        criteria: |
          - Wire AssetDeploymentService into create_install_service() factory
          - Add section header: "⚙️ Deploying nWave assets" after pipx install
          - Add spinner: "⏳ Installing to ~/.claude/..." during deployment
          - Spinner resolves to: "✅ Assets deployed ({duration})"
          - Show 4 detail lines with arrow notation (agents, commands, templates, scripts → paths)
          - Extract counts from InstallResult.asset_deployment_result
          - Walking skeleton test test_asset_deployment_output passes
        dependencies: ["09-05"]
        estimated_hours: 2

      - id: "10-04"
        name: "Add deployment validation section to forge_install.py"
        scenario: "tests/acceptance/forge_tui/test_walking_skeleton.py::TestWalkingSkeletonBuildToInstall::test_deployment_validation_output"
        criteria: |
          - Wire DeploymentValidationService into create_install_service() factory
          - Add section header: "🔍 Validating deployment" after asset deployment
          - Show 6 check lines (agents, commands, templates, scripts, manifest, schema)
          - Each check: "✅ {category} verified ({count})" or "❌ {category} verification failed"
          - Summary line: "✅ Deployment validated" or "❌ Deployment validation failed"
          - Extract results from InstallResult.deployment_validation_result
          - Walking skeleton test test_deployment_validation_output passes
        dependencies: ["10-03", "09-06"]
        estimated_hours: 2

      - id: "10-05"
        name: "Add SBOM manifest section to forge_install.py"
        scenario: "tests/acceptance/forge_tui/test_walking_skeleton.py::TestWalkingSkeletonBuildToInstall::test_sbom_dual_group_format"
        criteria: |
          - Add section header: "📋 What was installed" after deployment validation
          - Group 1 (CLI package): version, entry points, install path (3 dim lines)
          - Blank line separator
          - Group 2 (IDE assets): 6 dim lines with counts and paths (agents, commands, templates, scripts, config, manifest)
          - Extract CLI data from InstallResult (version, install_path)
          - Extract IDE data from InstallResult.asset_deployment_result
          - Walking skeleton test test_sbom_dual_group_format passes
        dependencies: ["10-04"]
        estimated_hours: 2

      - id: "10-06"
        name: "Add nWave assets health check to forge_install.py"
        scenario: "tests/acceptance/forge_tui/test_walking_skeleton.py::TestWalkingSkeletonBuildToInstall::test_health_includes_asset_check"
        criteria: |
          - In health verification section, add check line after "Core modules loadable"
          - Add: "✅ nWave assets accessible" (verifies ~/.claude/ assets are readable)
          - This may require a new HealthChecker check or inline verification
          - Walking skeleton test test_health_includes_asset_check passes
        dependencies: ["10-05"]
        estimated_hours: 1

      - id: "10-07"
        name: "Change celebration brand to nWave"
        scenario: "tests/acceptance/forge_tui/test_walking_skeleton.py::TestWalkingSkeletonBuildToInstall::test_celebration_uses_nwave_brand"
        criteria: |
          - In celebration line, replace "crafter-ai" with "nWave"
          - Change: "🎉 crafter-ai {version} installed and healthy!"
          - To: "🎉 nWave {version} installed and healthy!"
          - Keep package name "crafter-ai" in SBOM and other technical references
          - Walking skeleton test test_celebration_uses_nwave_brand passes
        dependencies: ["10-06"]
        estimated_hours: 0.5

      - id: "10-08"
        name: "Add Getting started section to forge_install.py"
        scenario: "tests/acceptance/forge_tui/test_walking_skeleton.py::TestWalkingSkeletonBuildToInstall::test_getting_started_section"
        criteria: |
          - Add section header: "📖 Getting started" after celebration
          - Show 5 dim lines with /nw: commands and descriptions
          - Commands: /nw:discuss, /nw:design, /nw:distill, /nw:develop, /nw:deliver
          - Format: "/nw:discuss  - Requirements gathering and business analysis"
          - Walking skeleton test test_getting_started_section passes
        dependencies: ["10-07"]
        estimated_hours: 1

      - id: "10-09"
        name: "Ensure version consistency across all displays"
        scenario: "tests/acceptance/forge_tui/test_walking_skeleton.py::TestWalkingSkeletonBuildToInstall::test_version_consistency_across_all_displays"
        criteria: |
          - Verify version from wheel METADATA appears in 5 locations
          - 1. Version display line (0.1.0 → 0.2.0)
          - 2. Wheel filename (crafter_ai-0.2.0-py3-none-any.whl)
          - 3. Install prompt (Install crafter-ai 0.2.0?)
          - 4. SBOM (crafter-ai 0.2.0 or crafter_ai 0.2.0)
          - 5. Celebration (nWave 0.2.0 installed and healthy!)
          - All must use InstallResult.version (single source of truth)
          - Walking skeleton test test_version_consistency_across_all_displays passes
        dependencies: ["10-08"]
        estimated_hours: 1

      - id: "10-10"
        name: "Verify full 17-step continuous stream ordering"
        scenario: "tests/acceptance/forge_tui/test_walking_skeleton.py::TestWalkingSkeletonBuildToInstall::test_output_reads_as_continuous_stream"
        criteria: |
          - All 25 ordered markers from Luna's design appear in correct sequence
          - Build: header, preflight, version, wheel, validation, IDE bundle, complete
          - Prompt: Install crafter-ai 0.2.0?
          - Install: header, preflight, backup, CLI install, deploy, validation, SBOM, health
          - Celebrate: celebration, getting started
          - No missing markers, no out-of-order markers
          - Walking skeleton test test_output_reads_as_continuous_stream passes
          - ALL 25 walking skeleton tests GREEN (0 failures)
        dependencies: ["10-09"]
        estimated_hours: 1

# ==============================================================================
# SUMMARY
# ==============================================================================

summary:
  total_phases: 10
  total_steps: 67
  estimated_total_hours: 168.5

  phase_breakdown:
    - phase: "00"
      name: "Sprint 0 Prerequisites"
      steps: 5
      hours: 9
      type: "infrastructure"
    - phase: "01"
      name: "Infrastructure"
      steps: 8
      hours: 23
      type: "feature"
    - phase: "02"
      name: "Journey 1 - Build"
      steps: 9
      hours: 28
      type: "feature"
    - phase: "03"
      name: "Journey 2 - Install"
      steps: 10
      hours: 28
      type: "feature"
      notes: "Step 03-05 split into 03-05a (3h) and 03-05b (2h) for safer TDD cycles"
    - phase: "04"
      name: "Journey 3 - PyPI"
      steps: 8
      hours: 22
      type: "feature"
    - phase: "05"
      name: "Cross-Cutting"
      steps: 4
      hours: 11
      type: "feature"
    - phase: "06"
      name: "Horizontal Coherence"
      steps: 5
      hours: 13
    - phase: "07"
      name: "TUI Redesign Happy Path"
      steps: 7
      hours: 20
      type: "feature"
    - phase: "08"
      name: "TUI Error States"
      steps: 5
      hours: 13
      type: "feature"
      status: "planned"
    - phase: "09"
      name: "Unified Install Pipeline Integration"
      steps: 8
      hours: 21
      type: "feature"
      status: "completed"
      notes: "Backend services: constants -> infrastructure -> 4 services -> 2 integrations"
    - phase: "10"
      name: "Full Installation Journey (Walking Skeleton Integration)"
      steps: 10
      hours: 13.5
      type: "validation"
      status: "in_progress"
      notes: "Wire backend services to CLI layer: 10 RED tests → 0 RED (all 25 GREEN)"

  p0_coverage:
    total_p0_stories: 23
    steps_covering_p0: 33
    coverage: "100%"

  acceptance_test_mapping:
    journey_1_build_feature: 30
    journey_2_install_feature: 47
    journey_3_pypi_feature: 44
    horizontal_coherence_feature: 26
    testpypi_coherence_feature: 32
    unified_pipeline_integration: 40
    total_scenarios: 219

  quality_gates:
    step_to_file_ratio: 1.84  # 57 steps / ~31 production files
    phase_09_decomposition_ratio: 1.33  # 8 steps / 6 production files
    identical_pattern_batching: "Applied (e.g., core checks batched)"
    behavioral_criteria_only: true
    no_private_method_references: true
    dag_valid: true

  risks_and_decisions:
    - decision: "Phase 00 as blocking prerequisite"
      rationale: "pyproject.toml and PyPI secrets are fundamental blockers"
    - decision: "Separate infrastructure steps from feature steps"
      rationale: "Clear distinction between platform setup and feature development"
    - decision: "Doctor command shared between Journey 2 and 3"
      rationale: "Horizontal coherence requirement - identical format and checks"
    - decision: "Auto-repair as separate steps"
      rationale: "Fixable checks are enhancements to base pre-flight framework"
    - decision: "Phase 09 uses optional constructor injection"
      rationale: "Preserves backward compatibility for existing BuildService and InstallService consumers (ADR-001)"
    - decision: "Shared constants module as Phase 09 first step"
      rationale: "Single source of truth for counts (30/23/17/4) prevents magic number drift (ADR-003)"
    - decision: "Walking skeleton order for Phase 09"
      rationale: "Constants -> infrastructure -> simplest service -> complex services -> integration"

# ==============================================================================
# PHASE 09 REVIEW
# ==============================================================================

phase_09_review:
  reviewer: "solution-architect-reviewer"
  date: "2026-02-05"
  verdict: "APPROVED"

  summary: |
    Phase 09 is well-structured with clear Outside-In TDD sequencing, correct
    dependency graph, behavioral acceptance criteria, and strong alignment with
    Morgan's approved integration architecture. The 8 steps map cleanly to 7
    production files (ratio 1.14) with zero validation-only steps. The DAG is
    acyclic, parallelization of steps 09-03 through 09-06 is correctly identified,
    and the capstone integration sequence (09-07 before 09-08) follows the
    architecture's data flow. One high finding: the summary section totals were
    not updated to include Phase 09 counts.

  findings:
    critical: []

    high:
      - id: "H-01"
        title: "Summary section totals not updated for Phase 09"
        location: "summary section (lines 994-1063)"
        description: |
          total_steps shows 49 but should be 57 (phases 00-06 sum to 49,
          plus Phase 09 adds 8). estimated_total_hours shows 137 but phases
          00-06 sum to 134 hours plus Phase 09 adds 21 = 155 total.
          step_to_file_ratio shows 1.96 (49/~25) but should account for
          Phase 09 files (~57/~31 = ~1.84). These stale totals will mislead
          planning and progress tracking.
        recommendation: |
          Update summary: total_steps to 57, estimated_total_hours to 155,
          step_to_file_ratio to ~1.84. Run a summation pass over all
          phase_breakdown entries to confirm.

    medium:
      - id: "M-01"
        title: "Step 09-02 has unnecessary dependency on 09-01"
        location: "step 09-02 dependencies (line 890)"
        description: |
          The copy_file extension to InMemoryFileSystemAdapter does not
          require ide_bundle_constants.py to exist. These two infrastructure
          tasks are independent and could run in parallel. The dependency
          forces sequential execution of two 1-hour tasks.
        recommendation: |
          Change 09-02 dependencies from ["09-01"] to []. Both 09-01 and
          09-02 become independent roots, and steps 09-03 through 09-06
          depend on both. This saves no time in practice (1 hour) but
          makes the DAG more accurate.

    low:
      - id: "L-01"
        title: "Integration test mapping in 09-07 and 09-08 is imprecise"
        location: "steps 09-07 and 09-08 scenario fields"
        description: |
          Step 09-07 references "(build-side tests)" and 09-08 references
          "(install-side tests)" in test_unified_pipeline_integration.py,
          but this file contains 12 test classes. Several tests (backup scope,
          health check, version flow, command count) do not depend on any
          Phase 09 service implementation and will pass without Phase 09 work.
          The scenario field should clarify which specific test classes each
          step targets.
        recommendation: |
          Optional improvement for developer clarity. Current mapping is
          sufficient since the step criteria describe the expected behavior,
          and the developer can identify which tests to target from the
          criteria alone.

  decomposition_check:
    total_steps: 8
    infrastructure_steps: 2
    implementation_steps: 4
    integration_steps: 2
    production_files: 7
    # ide_bundle_constants.py, ide_bundle_exists_check.py,
    # ide_bundle_build_service.py, asset_deployment_service.py,
    # deployment_validation_service.py, build_service.py, install_service.py
    ratio: 1.14
    validation_only_steps: 0
    identical_pattern_batching: "N/A - each service has distinct behavior"
    verdict: "PASS"

  dependency_graph_check:
    dag_valid: true
    cycles_detected: false
    parallel_opportunities: "09-03, 09-04, 09-05, 09-06 (after 09-01 and 09-02)"
    capstone_sequence: "09-07 (build integration) before 09-08 (install integration)"
    verdict: "PASS"

  architecture_alignment_check:
    adr_001_optional_injection: "Steps 09-07 and 09-08 criteria match ADR-001 pattern"
    adr_002_filesystem_port: "All service criteria use FileSystemPort type, not InMemoryFileSystemAdapter"
    adr_003_shared_constants: "Step 09-01 creates constants module as ADR-003 specifies"
    adr_004_port_type_hint: "Criteria correctly specify FileSystemPort as constructor type"
    walking_skeleton_alignment: "Implementation sequence matches architecture document section 'Implementation Sequence'"
    verdict: "PASS"

  acceptance_criteria_check:
    behavioral_criteria: true
    implementation_coupling_detected: false
    private_method_references: false
    test_file_references_correct: true
    test_counts_match:
      test_deployment_checks: "4 tests (matches step 09-03 reference)"
      test_ide_bundle_build_service: "8 tests (matches step 09-04 reference)"
      test_asset_deployment_service: "8 tests (matches step 09-05 reference)"
      test_deployment_validation_service: "8 tests (matches step 09-06 reference)"
      test_unified_pipeline_integration: "12 tests (matches steps 09-07 and 09-08)"
    verdict: "PASS"

  recommendation: |
    APPROVED for implementation. Fix H-01 (summary totals) before the next
    planning session to prevent stale metrics from misleading progress tracking.
    M-01 and L-01 are optional improvements that do not block implementation.
    The developer (Crafter) can proceed with Phase 09 steps in the defined
    order using WIP contract protocol.
