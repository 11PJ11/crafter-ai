# ═══════════════════════════════════════════════════════════════════════════════
# WIP.yaml - Work In Progress Contract
# Generated by: Vera (Orchestrator)
# Protocol Version: 0.1
# ═══════════════════════════════════════════════════════════════════════════════

meta:
  generated_at: "2026-02-03T05:30:00Z"
  project: "modern-cli-installer"
  phase: "05"
  phase_name: "Cross-Cutting Concerns"

# ─────────────────────────────────────────────────────────────────────────────
# STEP CONTRACT
# ─────────────────────────────────────────────────────────────────────────────
step:
  id: "05-03"
  name: "Create integration checkpoint display"
  agent: "software-crafter"
  estimated_hours: 2
  dependencies_satisfied: true
  user_stories: ["US-003"]

# ─────────────────────────────────────────────────────────────────────────────
# CRITICAL: OUTSIDE-IN TDD ENFORCEMENT
# ─────────────────────────────────────────────────────────────────────────────
tdd_approach:
  method: "OUTSIDE-IN"

  driving_test:
    file: "docs/features/modern-cli-installer/03-distill/e2e-scenarios/test_horizontal_coherence.py"
    function: "test_integration_checkpoint_displays_at_build_to_install_transition"
    feature_file: "docs/features/modern-cli-installer/03-distill/features/horizontal_coherence.feature"
    scenario: "Integration checkpoint displays at build-to-install transition"

  execution_order:
    step_1:
      action: "Run the E2E test FIRST"
      command: "pytest docs/features/modern-cli-installer/03-distill/e2e-scenarios/ -k 'checkpoint' -v --tb=short 2>&1 | head -100"
      expected: "FAIL (missing CheckpointService or NotImplementedError)"
      purpose: "See the failing test that will drive implementation"

    step_2:
      action: "Write unit tests for IntegrationCheckpointService"
      file: "tests/installer/services/test_integration_checkpoint_service.py"
      purpose: "Define expected behavior through tests"

    step_3:
      action: "Implement IntegrationCheckpointService"
      file: "src/crafter_ai/installer/services/integration_checkpoint_service.py"
      purpose: "Make unit tests pass"

    step_4:
      action: "Run E2E test again"
      command: "pytest docs/features/modern-cli-installer/03-distill/e2e-scenarios/ -k 'checkpoint' -v --tb=short 2>&1 | head -100"
      expected: "Test progresses further (may still fail on full wiring)"
      purpose: "Verify service integration"

# ─────────────────────────────────────────────────────────────────────────────
# INPUT: What the agent receives (READ-ONLY context)
# ─────────────────────────────────────────────────────────────────────────────
input:
  source_file: "src/crafter_ai/installer/services/integration_checkpoint_service.py"
  test_file: "tests/installer/services/test_integration_checkpoint_service.py"

  existing_code:
    artifact_registry: "src/crafter_ai/installer/domain/artifact_registry.py"
    wheel_validation: "src/crafter_ai/installer/services/wheel_validation_service.py"
    progress_display: "src/crafter_ai/installer/services/progress_display_service.py"

  e2e_scenarios:
    - "horizontal_coherence.feature::Integration checkpoint displays at build-to-install transition"
    - "horizontal_coherence.feature::Integration checkpoint verifies version consistency"
    - "horizontal_coherence.feature::Integration checkpoint verifies count consistency"
    - "horizontal_coherence.feature::Integration checkpoint blocks on version mismatch"

  requirements:
    checkpoint_service:
      - "IntegrationCheckpointService uses ArtifactRegistry via dependency injection"
      - "verify_checkpoint(expected: CheckpointData, actual: CheckpointData) -> CheckpointResult"
      - "CheckpointData dataclass: version, wheel_path, agent_count, command_count, template_count"
      - "CheckpointResult dataclass: passed, mismatches list, display_data"

    verification_checks:
      - "Version matches build: compare expected vs actual version strings"
      - "Wheel path verified: check path exists and matches expected"
      - "Artifact counts consistent: agent_count, command_count, template_count all match"

    display_format:
      - "Header: 'INTEGRATION CHECKPOINT' in a box"
      - "Each check shows: check name + checkmark (if passed) or X (if failed)"
      - "On mismatch: show 'Expected: X' and 'Found: Y' details"
      - "Returns display-ready data for CLI to render"

    checkpoint_data:
      - "CheckpointData frozen dataclass with:"
      - "  - version: str"
      - "  - wheel_path: Path | None"
      - "  - agent_count: int"
      - "  - command_count: int"
      - "  - template_count: int"

    checkpoint_result:
      - "CheckpointResult dataclass with:"
      - "  - passed: bool (all checks passed)"
      - "  - mismatches: list[str] (description of each mismatch)"
      - "  - version_match: bool"
      - "  - wheel_path_match: bool"
      - "  - counts_match: bool"
      - "  - display_lines: list[str] (formatted output lines)"

    error_handling:
      - "Version mismatch: return detailed mismatch info"
      - "Wheel path mismatch: return expected vs actual paths"
      - "Count mismatch: show which count differs and by how much"

  test_requirements:
    - "Test verify_checkpoint passes when all data matches"
    - "Test verify_checkpoint fails when version mismatches"
    - "Test verify_checkpoint fails when wheel_path mismatches"
    - "Test verify_checkpoint fails when counts mismatch"
    - "Test display_lines includes 'INTEGRATION CHECKPOINT' header"
    - "Test display_lines shows checkmarks for passed checks"
    - "Test display_lines shows X for failed checks"
    - "Test mismatch details show expected vs actual values"

# ─────────────────────────────────────────────────────────────────────────────
# CONSTRAINTS: Rules the agent MUST follow
# ─────────────────────────────────────────────────────────────────────────────
constraints:
  max_tool_calls: 30
  must_run_tests: true
  fail_fast: true

  mandatory_sequence:
    - "1. Run E2E checkpoint tests FIRST (see them fail)"
    - "2. Write unit tests for IntegrationCheckpointService"
    - "3. Implement IntegrationCheckpointService to make unit tests pass"
    - "4. Run E2E test again (verify progress)"
    - "5. Run all unit tests"
    - "6. Commit changes"

  allowed_actions:
    - "Read existing ArtifactRegistry"
    - "Read E2E test files"
    - "Read progress_display_service.py as pattern reference"
    - "Create IntegrationCheckpointService source file"
    - "Create IntegrationCheckpointService test file"
    - "Run pytest on unit tests"
    - "Run pytest on E2E tests"
    - "Commit changes"

  forbidden_actions:
    - "DO NOT skip running E2E test first"
    - "DO NOT modify ArtifactRegistry"
    - "DO NOT read roadmap.yaml or execution-status.yaml"
    - "DO NOT wire to CLI (this is service layer only)"

# ─────────────────────────────────────────────────────────────────────────────
# OUTPUT: What the agent must deliver (AGENT FILLS THIS SECTION)
# ─────────────────────────────────────────────────────────────────────────────
output:
  status: complete

  e2e_test_before:
    command: "pytest docs/features/modern-cli-installer/03-distill/e2e-scenarios/ -k 'checkpoint' -v --tb=short"
    result: "FAILED"
    failure_reason: "NotImplementedError: Production code needed for JourneyTransitionService and InstallJourney"

  artifacts_created:
    - "src/crafter_ai/installer/services/integration_checkpoint_service.py"
    - "tests/installer/services/test_integration_checkpoint_service.py"

  unit_test_result:
    command: "pytest tests/installer/services/test_integration_checkpoint_service.py -v"
    tests_passed: 21
    tests_failed: 0

  e2e_test_after:
    command: "pytest docs/features/modern-cli-installer/03-distill/e2e-scenarios/ -k 'checkpoint' -v --tb=short"
    result: "FAILED"
    failure_reason: "Service layer complete; E2E still needs JourneyTransitionService wiring (separate step)"

  commit_hash: "b4f9db2"
  commit_message: "feat(installer): add integration checkpoint service for build-to-install verification"
  notes: "IntegrationCheckpointService complete with CheckpointData and CheckpointResult dataclasses. 21 unit tests pass. E2E tests fail on wiring layer (JourneyTransitionService), not on checkpoint service - this is expected per WIP.yaml scope."

# ─────────────────────────────────────────────────────────────────────────────
# SUCCESS CRITERIA
# ─────────────────────────────────────────────────────────────────────────────
success_criteria:
  - criterion: "E2E test ran BEFORE implementation"
    validation: "output.e2e_test_before.result is not empty"

  - criterion: "IntegrationCheckpointService created with verify_checkpoint method"
    validation: "src/crafter_ai/installer/services/integration_checkpoint_service.py exists"

  - criterion: "CheckpointData and CheckpointResult dataclasses created"
    validation: "Dataclasses defined in service module"

  - criterion: "Unit tests pass"
    validation: "output.unit_test_result.tests_failed == 0"

  - criterion: "Service provides display-ready output"
    validation: "CheckpointResult.display_lines returns formatted strings"
